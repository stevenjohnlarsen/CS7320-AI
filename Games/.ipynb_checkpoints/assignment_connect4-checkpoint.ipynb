{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Playing Connect 4\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: Undegraduates 10, graduate students 11\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play Connect 4:\n",
    "\n",
    "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the Search Problem [1 point]\n",
    "\n",
    "Define the components of the search problem:\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model\n",
    "* Goal state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Initial state\n",
    " * Empty board and it is marked as someones turn.\n",
    "* Actions\n",
    " * Either player can play in either column, as long as there isn't 6 pieces in that column.\n",
    "* Transition model\n",
    " * Given a state and an action, the next state is the same board with one more piece on the lowest availble space of the chosen action.\n",
    "* Goal state\n",
    " * Goal States for both players is all states with 4 or more in a diagonal ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the search space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ The search space for a $6 \\times 7$ board is large. You can experiment with smaller boards (the smallest is $4 times \\4$) and/or changing the winning rule to connect 3 instead of 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Game Environment and Random Agent [2 point]\n",
    "\n",
    "Use a numpy character array as the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the board and helper functions for:\n",
    "\n",
    "* The transition model (result).\n",
    "* The utility function.\n",
    "* Check for terminal states.\n",
    "* A check for available actions.\n",
    "* A function to visualize the board.\n",
    "\n",
    "Make sure that all these functions work with boards of different sizes.\n",
    "\n",
    "Implement an agent that plays randomly and let two random agents play against each other 1000 times. How often does each player win? Is the result expected? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "def empty_board(shape=(6, 7)):\n",
    "    return np.full(shape=shape, fill_value=' ')\n",
    "\n",
    "def show_board(board):\n",
    "    for row in board:\n",
    "        line = '|'\n",
    "        for char in row:\n",
    "            line += char +  '|'\n",
    "        print(line)\n",
    "    print('_' * (2*len(board[0]) + 1))\n",
    "show_board(empty_board())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of colors for the players use 'x' and 'o' to represent the players. Make sure that your agent functions all have the from: `agent_type(board, player = 'x')`, where board is the current board position and player is the player whose next move it is and who the agent should play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def to_move(board, player, move):\n",
    "    new_board = board.copy()\n",
    "    for row in reversed(new_board):\n",
    "        if row[move] == ' ':\n",
    "            row[move] = player\n",
    "            return new_board\n",
    "    return board\n",
    "#helper for utility functions\n",
    "def diagonal_rows(arr):\n",
    "    rows = []\n",
    "    num_rows = len(arr)\n",
    "    num_cols = len(arr[0])\n",
    "    arr = np.asarray(arr)\n",
    "    arr2 = arr.copy()\n",
    "    arr2 = np.fliplr(arr2)\n",
    "    for i in range((-1)*max(num_cols,num_rows),max(num_cols,num_rows)):\n",
    "        possible_arr = np.diagonal(arr,i,axis1=0,axis2=1)\n",
    "        if len(possible_arr) != 0:\n",
    "            rows.append(possible_arr)\n",
    "        possible_arr = np.diagonal(arr2,i,axis1=0,axis2=1)\n",
    "        if len(possible_arr) != 0:\n",
    "            rows.append(possible_arr)\n",
    "    return rows\n",
    "def switch_player(player):\n",
    "    if player == 'x':\n",
    "        return 'o'\n",
    "    else:\n",
    "        return 'x'\n",
    "\n",
    "def utility(board, player):\n",
    "    opponent = switch_player(player)\n",
    "    #check if there is a horizonatal winner\n",
    "    for row in board:\n",
    "        for x in range(0, len(row) - 3):\n",
    "            if row[x] == player and row[x + 1] == player and row[x + 2] == player and row[x + 3] == player:\n",
    "                return 1\n",
    "            if row[x] == opponent and row[x + 1] == opponent and row[x + 2] == opponent and row[x + 3] == opponent:\n",
    "                return -1\n",
    "    #check if there is a vertical winner\n",
    "    vertical_board = board.copy()\n",
    "    vertical_board = np.rot90(vertical_board)\n",
    "    for row in vertical_board:\n",
    "        for x in range(0, len(row) - 3):\n",
    "            if row[x] == player and row[x + 1] == player and row[x + 2] == player and row[x + 3] == player:\n",
    "                return 1\n",
    "            if row[x] == opponent and row[x + 1] == opponent and row[x + 2] == opponent and row[x + 3] == opponent:\n",
    "                return -1\n",
    "    rows = len(board)\n",
    "    columns = len(board[0])\n",
    "    #check diagonal\n",
    "    for row in diagonal_rows(board):\n",
    "        for x in range(0, len(row) - 3):\n",
    "            if row[x] == player and row[x + 1] == player and row[x + 2] == player and row[x + 3] == player:\n",
    "                return 1\n",
    "            if row[x] == opponent and row[x + 1] == opponent and row[x + 2] == opponent and row[x + 3] == opponent:\n",
    "                return -1\n",
    "    if len(actions(board))==0:\n",
    "        return 0\n",
    "    return None\n",
    "\n",
    "def actions(board):\n",
    "    options = []\n",
    "    for i in range(0,len(board[0])):\n",
    "        if board[0][i] == ' ':\n",
    "            options.append(i)\n",
    "    return options\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class random_agent:\n",
    "    def __init__(self,character):\n",
    "        self.character = character\n",
    "    \n",
    "    def act(self, board):\n",
    "        moves = actions(board)\n",
    "        move_int = random.choice(moves)\n",
    "        return to_move(board, self.character,move_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([13]), array([16]), array([ 9, 14]), array([12, 15]), array([ 4, 10, 15]), array([ 7, 11, 14]), array([ 1,  5, 11, 16]), array([ 4,  6, 10, 13]), array([ 2,  6, 12]), array([3, 5, 9]), array([3, 7]), array([2, 4]), array([4]), array([1])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arr = [[1,2,3,4],\n",
    "       [4,5,6,7],\n",
    "       [9,10,11,12],\n",
    "       [13,14,15,16]]\n",
    "diag = diagonal_rows(arr)\n",
    "print(diag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|x| | | | | | |\n",
      "_______________\n",
      "None\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|x| | | | | | |\n",
      "|x| | | | | | |\n",
      "|x| | | | | | |\n",
      "|x| | | | | | |\n",
      "_______________\n",
      "1\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|x| | | | | | |\n",
      "|x| | | | | | |\n",
      "|x|o|o|o|o| | |\n",
      "_______________\n",
      "-1\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | |x| | | |\n",
      "|x| |x|o| | | |\n",
      "|x|x|o|o| | | |\n",
      "|x|o|o|o| | | |\n",
      "_______________\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Testing some of these functions\n",
    "\n",
    "\n",
    "board = empty_board()\n",
    "show_board(board)\n",
    "board = to_move(board,'x',0)\n",
    "show_board(board)\n",
    "print(utility(board,'x'))\n",
    "board = to_move(board,'x',0)\n",
    "board = to_move(board,'x',0)\n",
    "board2 = to_move(board,'x',0)\n",
    "show_board(board2)\n",
    "print(utility(board2,'x'))\n",
    "\n",
    "\n",
    "board = to_move(board,'o',1)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'o',3)\n",
    "board3 = to_move(board,'o',4)\n",
    "show_board(board3)\n",
    "print(utility(board3,'x'))\n",
    "\n",
    "board = to_move(board,'x',1)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',3)\n",
    "board = to_move(board,'o',3)\n",
    "board4 = to_move(board,'x',3)\n",
    "show_board(board4)\n",
    "print(utility(board4,'x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_randoms(n,shape=(6,7),print_boards=False):\n",
    "    x_wins = 0\n",
    "    o_wins = 0\n",
    "    draws = 0\n",
    "    for i in range(0,n):\n",
    "        board = empty_board(shape=shape)\n",
    "        agent1 = random_agent('x')\n",
    "        agent2 = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = agent1.act(board)\n",
    "            if utility(board, agent1.character) == 1:\n",
    "                winner = agent1.character\n",
    "                x_wins = x_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = agent2.act(board)\n",
    "            if utility(board, agent2.character) == 1:\n",
    "                winner = agent2.character\n",
    "                o_wins = o_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            print(board)\n",
    "    return (x_wins, o_wins, draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5526, 4449, 29)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_randoms(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3: Minimax Search with Alpha-Beta Pruning [4 points]\n",
    "\n",
    "### Implement the search starting from a given board and specifying the player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEBUG = 1 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "\n",
    "def alpha_beta_search(board, player = 'x'):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    \n",
    "    value, move = max_value_ab(board, player, -math.inf, +math.inf)\n",
    "    \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched: {COUNT}\") \n",
    "    \n",
    "    return value, move\n",
    "\n",
    "def max_value_ab(state, player, alpha, beta):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "       \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"max: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "        \n",
    "    v, move = -math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = min_value_ab(to_move(state, player, a), player, alpha, beta)\n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta: return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def min_value_ab(state, player, alpha, beta):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"min: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = max_value_ab(to_move(state, switch_player(player), a), player, alpha, beta)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        if v <= alpha: return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with some manually created boards (at least 5) to check if the agent spots wining opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes searched: 6\n",
      "(1, 3)\n",
      "Number of nodes searched: 10\n",
      "(1, 3)\n",
      "|o|o|o| | |\n",
      "|o|o|o| |x|\n",
      "|x|x|x| |o|\n",
      "|o|o|o| |o|\n",
      "|x|x|x| |o|\n",
      "___________\n",
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'x'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'o'\n",
    "board[3][2] = 'o'\n",
    "board[2][0] = 'x'\n",
    "board[2][1] = 'x'\n",
    "board[2][2] = 'x'\n",
    "board[1][0] = 'o'\n",
    "board[1][1] = 'o'\n",
    "board[1][2] = 'o'\n",
    "board[0][0] = 'o'\n",
    "board[0][1] = 'o'\n",
    "board[0][2] = 'o'\n",
    "board[4][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "board[1][4] = 'x'\n",
    "move = alpha_beta_search(board, player = 'x')\n",
    "print(move)\n",
    "move = alpha_beta_search(board, player = 'o')\n",
    "print(move)\n",
    "show_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes searched: 171286\n",
      "(0, 4)\n",
      "Number of nodes searched: 24203\n",
      "(1, 0)\n",
      "| | | | | |\n",
      "| | | | | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'o'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'o'\n",
    "board[3][2] = 'x'\n",
    "board[2][0] = 'x'\n",
    "board[2][1] = 'x'\n",
    "board[2][2] = 'o'\n",
    "board[4][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "move = alpha_beta_search(board, player = 'x')\n",
    "print(move)\n",
    "\n",
    "move = alpha_beta_search(board, player = 'o')\n",
    "print(move)\n",
    "show_board(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something looks off about 'o's move.  We are going to investigate this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | |\n",
      "|o| | | | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'o'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'o'\n",
    "board[3][2] = 'x'\n",
    "board[2][0] = 'x'\n",
    "board[2][1] = 'x'\n",
    "board[2][2] = 'o'\n",
    "board[4][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "board = to_move(board, 'o',0)\n",
    "show_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes searched: 23716\n",
      "(-1, 0)\n"
     ]
    }
   ],
   "source": [
    "move = alpha_beta_search(board, player = 'x')\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|x| | | | |\n",
      "|o| | | | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Number of nodes searched: 1613\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "board = to_move(board, 'x',0)\n",
    "show_board(board)\n",
    "move = alpha_beta_search(board, player = 'o')\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|x| | | | |\n",
      "|o|o| | | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Number of nodes searched: 1299\n",
      "(0, 4)\n"
     ]
    }
   ],
   "source": [
    "board = to_move(board, 'o',1)\n",
    "show_board(board)\n",
    "move = alpha_beta_search(board, player = 'x')\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|x| | | | |\n",
      "|o|o| | | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Number of nodes searched: 85\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "board = to_move(board, 'x',0)\n",
    "show_board(board)\n",
    "move = alpha_beta_search(board, player = 'o')\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|x|o| | | |\n",
      "|o|o| | | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Number of nodes searched: 64\n",
      "(-1, 2)\n"
     ]
    }
   ],
   "source": [
    "board = to_move(board, 'o',1)\n",
    "show_board(board)\n",
    "move = alpha_beta_search(board, player = 'x')\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|x|o| | | |\n",
      "|o|o|x| | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Number of nodes searched: 29\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "board = to_move(board, 'x',2)\n",
    "show_board(board)\n",
    "move = alpha_beta_search(board, player = 'o')\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|x|o|o| | |\n",
      "|o|o|x| | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Number of nodes searched: 23\n",
      "(-1, 3)\n"
     ]
    }
   ],
   "source": [
    "board = to_move(board, 'o',2)\n",
    "show_board(board)\n",
    "move = alpha_beta_search(board, player = 'x')\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|x|o|o| | |\n",
      "|o|o|x| | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o|x|o|\n",
      "___________\n",
      "Number of nodes searched: 3\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "board = to_move(board, 'x',3)\n",
    "show_board(board)\n",
    "move = alpha_beta_search(board, player = 'o')\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|x|o|o| | |\n",
      "|o|o|x| | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x|o|o|\n",
      "|x|x|o|x|o|\n",
      "___________\n"
     ]
    }
   ],
   "source": [
    "board = to_move(board, 'o',3)\n",
    "show_board(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It still won in the end.  We are going to do some other tests.  The problem we are experiencing with MiniMax is wit is a depth first search, and does not find the fastest solution, but a solution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes searched: 3122\n",
      "(1, 3)\n",
      "| | |x| | |\n",
      "| | |o| | |\n",
      "| | |x|o| |\n",
      "| |x|o|x|x|\n",
      "|x|o|x|o|o|\n",
      "___________\n",
      "Wall time: 390 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'x',0)\n",
    "board = to_move(board,'o',1)\n",
    "board = to_move(board,'x',1)\n",
    "board = to_move(board,'o',3)\n",
    "board = to_move(board,'x',3)\n",
    "board = to_move(board,'o',4)\n",
    "board = to_move(board,'x',4)\n",
    "board = to_move(board,'o',3)\n",
    "move = alpha_beta_search(board, player = 'x')\n",
    "print(move)\n",
    "show_board(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | |\n",
      "| | | | | |\n",
      "| | | | | |\n",
      "| | | | | |\n",
      "___________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36malpha_beta_search\u001b[1;34m(board, player)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mCOUNT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Number of nodes searched: {COUNT}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmax_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmin_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmax_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmin_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmax_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmin_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmax_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmin_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmax_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmin_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmax_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmin_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmax_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmin_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmax_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmin_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmax_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmin_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmax_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmin_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-9dc0a95380f9>\u001b[0m in \u001b[0;36mmax_value_ab\u001b[1;34m(state, player, alpha, beta)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# return utility of state is a terminal state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-b0f389d67516>\u001b[0m in \u001b[0;36mutility\u001b[1;34m(board, player)\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m#check if there is a vertical winner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mvertical_board\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mvertical_board\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvertical_board\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvertical_board\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((4,5))\n",
    "show_board(board)\n",
    "move = alpha_beta_search(board, player = 'x')\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move ordering\n",
    "\n",
    "Describe and implement a simple move ordering strategy. How does this strategy influence the time it takes to \n",
    "make a move?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions_ordering1(board, player='x'):\n",
    "    options = []\n",
    "    win_options = []\n",
    "    for i in range(0,len(board[0])):\n",
    "        if board[0][i] == ' ':\n",
    "            potential_board = to_move(board,player,i)\n",
    "            \n",
    "            if utility(potential_board, player) != None:\n",
    "                win_options.append(i)\n",
    "            else:\n",
    "                options.append(i)\n",
    "    print('win',win_options)\n",
    "    print('other', options)\n",
    "    return win_options + options\n",
    "\n",
    "def alpha_beta_search_ordering1(board, player = 'x'):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    \n",
    "    value, move = max_value_ab(board, player, -math.inf, +math.inf)\n",
    "    \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched: {COUNT}\") \n",
    "    \n",
    "    return value, move\n",
    "\n",
    "def max_value_ab_ordering1(state, player, alpha, beta):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "       \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"max: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "        \n",
    "    v, move = -math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in actions_ordering1(state, player):\n",
    "        v2, a2 = min_value_ab(to_move(state, player, a), player, alpha, beta)\n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta: return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def min_value_ab_ordering1(state, player, alpha, beta):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"min: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in actions_ordering1(state,switch_player(player)):\n",
    "        v2, a2 = max_value_ab(to_move(state, switch_player(player), a), player, alpha, beta)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        if v <= alpha: return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | |x| | |\n",
      "| | |o| | |\n",
      "| | |x|o| |\n",
      "| |x|o|x|x|\n",
      "|x|o|x|o|o|\n",
      "___________\n",
      "Number of nodes searched: 3122\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "board = empty_board((5,5))\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'x',0)\n",
    "board = to_move(board,'o',1)\n",
    "board = to_move(board,'x',1)\n",
    "board = to_move(board,'o',3)\n",
    "board = to_move(board,'x',3)\n",
    "board = to_move(board,'o',4)\n",
    "board = to_move(board,'x',4)\n",
    "board = to_move(board,'o',3)\n",
    "show_board(board)\n",
    "move = alpha_beta_search_ordering1(board, 'x')\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | |x| | |\n",
      "| | |o| | |\n",
      "| | |x| | |\n",
      "| | |o| | |\n",
      "|o| |x| | |\n",
      "___________\n",
      "Number of nodes searched: 1127129\n",
      "(1, 1)\n",
      "Number of nodes searched: 1127129\n",
      "(1, 1)\n",
      "Wall time: 4min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',0)\n",
    "show_board(board)\n",
    "move = alpha_beta_search_ordering1(board, player = 'x')\n",
    "print(move)\n",
    "\n",
    "move = alpha_beta_search(board, player = 'x')\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ordering does not seem to reduce the nodes we explore.  We will try another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions_ordering2(board):\n",
    "    options = []\n",
    "    win_options = []\n",
    "    for i in range(0,len(board[0])):\n",
    "        if board[0][i] == ' ':\n",
    "            options.append(i)\n",
    "    order = []\n",
    "    #get the middle element\n",
    "    print(options)\n",
    "    if len(options) % 2 == 1:\n",
    "        order.append(options[len(options)//2])\n",
    "        for i in range(1,(len(options)//2)+1):\n",
    "            order.append(len(options)//2 + i)\n",
    "            order.append(len(options)//2 - i)\n",
    "    else:\n",
    "        for i in range(1,(len(options)//2)+1):\n",
    "            order.append(len(options)//2 + (i-1))\n",
    "            order.append(len(options)//2 - i)\n",
    "    options = [options[i] for i in order]\n",
    "    return options\n",
    "\n",
    "def alpha_beta_search_ordering2(board, player = 'x'):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    \n",
    "    value, move = max_value_ab(board, player, -math.inf, +math.inf)\n",
    "    \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched: {COUNT}\") \n",
    "    \n",
    "    return value, move\n",
    "\n",
    "def max_value_ab_ordering2(state, player, alpha, beta):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "       \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"max: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "        \n",
    "    v, move = -math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in actions_ordering2(state):\n",
    "        v2, a2 = min_value_ab(to_move(state, player, a), player, alpha, beta)\n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta: return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def min_value_ab_ordering2(state, player, alpha, beta):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"min: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in actions_ordering2(state):\n",
    "        v2, a2 = max_value_ab(to_move(state, switch_player(player), a), player, alpha, beta)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        if v <= alpha: return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | |x| | |\n",
      "| | |o| | |\n",
      "| | |x| | |\n",
      "| | |o| | |\n",
      "|o| |x| | |\n",
      "___________\n",
      "Number of nodes searched: 1127129\n",
      "(1, 1)\n",
      "Number of nodes searched: 1127129\n",
      "(1, 1)\n",
      "Number of nodes searched: 1127129\n",
      "(1, 1)\n",
      "Wall time: 6min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',0)\n",
    "show_board(board)\n",
    "move = alpha_beta_search_ordering2(board, player = 'x')\n",
    "print(move)\n",
    "\n",
    "\n",
    "move = alpha_beta_search_ordering1(board, player = 'x')\n",
    "print(move)\n",
    "\n",
    "move = alpha_beta_search(board, player = 'x')\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes searched: 25994\n",
      "| | |x| | |\n",
      "| | |o|x| |\n",
      "| | |x|o|x|\n",
      "| |x|o|x|x|\n",
      "|x|o|x|o|o|\n",
      "___________\n"
     ]
    }
   ],
   "source": [
    "class minimax_agent:\n",
    "    def __init__(self,character):\n",
    "        self.character = character\n",
    "    \n",
    "    def act(self, board):\n",
    "        win, move_int = minimax_search(board, self.character)\n",
    "        return to_move(board, self.character,move_int)\n",
    "board = empty_board((5,5))\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'x',0)\n",
    "board = to_move(board,'o',1)\n",
    "board = to_move(board,'x',1)\n",
    "board = to_move(board,'o',3)\n",
    "board = to_move(board,'x',3)\n",
    "board = to_move(board,'o',4)\n",
    "board = to_move(board,'x',4)\n",
    "board = to_move(board,'o',3)\n",
    "board = to_move(board,'x',4)\n",
    "agent2 = minimax_agent('x')\n",
    "board = agent2.act(board)\n",
    "show_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes searched: 32988322\n",
      "Number of nodes searched: 2566477\n",
      "Number of nodes searched: 104029\n",
      "Number of nodes searched: 3299\n",
      "Number of nodes searched: 410\n",
      "Number of nodes searched: 31\n",
      "Number of nodes searched: 4\n",
      "Number of nodes searched: 2\n",
      "(0, 0, 1)\n",
      "Wall time: 53min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def run_random_vs_alpha(n,shape=(6,7),print_boards=False):\n",
    "    x_wins = 0\n",
    "    o_wins = 0\n",
    "    draws = 0\n",
    "    for i in range(0,n):\n",
    "        board = empty_board(shape=shape)\n",
    "        agent1 = random_agent('x')\n",
    "        agent2 = minimax_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = agent1.act(board)\n",
    "            if utility(board, agent1.character) == 1:\n",
    "                winner = agent1.character\n",
    "                x_wins = x_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = agent2.act(board)\n",
    "            if utility(board, agent2.character) == 1:\n",
    "                winner = agent2.character\n",
    "                o_wins = o_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            print(board)\n",
    "    return (x_wins, o_wins, draws)\n",
    "print(run_random_vs_alpha(1,(4,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search [3 points] \n",
    "\n",
    "### Heuristic evaluation function\n",
    "\n",
    "Define and implement a heuristic evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting off search \n",
    "\n",
    "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the same manually created boards as above to check if the agent spots wining opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pruning\n",
    "\n",
    "Add forward pruning to the cutoff search where you do not consider moves that have a low evaluation value after a shallow search \n",
    "(way smaller than the cuttoff value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function or different forward pruning) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge task [+ 1 bonus point]\n",
    "\n",
    "Find another student and let your best agent play against the other student's best player. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [1 point]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+1 Bonus point].\n",
    "\n",
    "### Pure Monte Carlos Search\n",
    "\n",
    "Implement Pure Monte Carlo Search and investigate how this search performs on the test boards that you have used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Move\n",
    "\n",
    "How would you determine what the best first move is? You can use Pure Monte Carlo Search or any algorithms \n",
    "that you have implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Function 1\n",
    "\n",
    "Player Score.\n",
    "* Any streak of 1 = 1 point\n",
    "* Any streak of 2 = 2 point\n",
    "* Any streak of 3 = 6 point\n",
    "\n",
    "The function returns target players score minus the opponents score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def unitility_function_1(board, player, move_int):\n",
    "    #check if there is a horizonatal winner\n",
    "    board = move(board=board,player=player,move=move_int)\n",
    "    num_ones_total = 0\n",
    "    num_twos_total = 0\n",
    "    num_threes_total = 0\n",
    "    num_fours_total = 0\n",
    "    for row in board:\n",
    "        num_ones, num_twos, num_threes,num_fours = score_array(row, player)\n",
    "        num_ones_total += num_ones\n",
    "        num_twos_total += num_twos\n",
    "        num_threes_total += num_threes\n",
    "        num_fours_total += num_fours\n",
    "        \n",
    "    #check if there is a vertical winner\n",
    "    vertical_board = board.copy()\n",
    "    vertical_board = np.rot90(vertical_board)\n",
    "    for row in vertical_board:\n",
    "        num_ones, num_twos, num_threes,num_fours = score_array(row, player)\n",
    "        num_twos_total += num_twos\n",
    "        num_threes_total += num_threes\n",
    "        num_fours_total += num_fours\n",
    "    for i in diagonal_rows(board):\n",
    "        num_ones, num_twos, num_threes,num_fours = score_array(i, player)\n",
    "        num_twos_total += num_twos\n",
    "        num_threes_total += num_threes\n",
    "        num_fours_total += num_fours\n",
    "    print(num_ones_total,num_twos_total,num_threes_total)\n",
    "    if num_fours_total > 0:\n",
    "        return 2**32\n",
    "    return num_ones_total + num_twos_total*2 + num_threes_total*6\n",
    "\n",
    "def score_array(array, player):\n",
    "    arr = array.copy()\n",
    "    np.insert(arr,obj=0,values=['*'])\n",
    "    np.insert(arr,obj=len(arr),values=['*'])\n",
    "    num_ones = 0\n",
    "    num_twos = 0\n",
    "    num_threes = 0\n",
    "    num_fours = 0\n",
    "    current_run = 0\n",
    "    for c in arr:\n",
    "        if c == player:\n",
    "            current_run += 1\n",
    "        else: \n",
    "            if current_run == 1:\n",
    "                num_ones += 1\n",
    "            elif current_run == 2:\n",
    "                num_twos += 1\n",
    "            elif current_run == 3:\n",
    "                num_threes +=1\n",
    "            elif current_run >= 4:\n",
    "                num_fours = 1\n",
    "            current_run = 0\n",
    "    return (num_ones,num_twos,num_threes,num_fours)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
