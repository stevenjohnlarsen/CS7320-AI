{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Playing Connect 4\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: Undegraduates 10, graduate students 11\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play Connect 4:\n",
    "\n",
    "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the Search Problem [1 point]\n",
    "\n",
    "Define the components of the search problem:\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model\n",
    "* Goal state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Initial state\n",
    " * Empty board and it is marked as someones turn.\n",
    "* Actions\n",
    " * Either player can play in either column, as long as there isn't 6 pieces in that column.\n",
    "* Transition model\n",
    " * Given a state and an action, the next state is the same board with one more piece on the lowest availble space of the chosen action.\n",
    "* Goal state\n",
    " * Goal States for both players is all states with 4 or more in a diagonal ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the search space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ The search space for a $6 \\times 7$ board is large. You can experiment with smaller boards (the smallest is $4 times \\4$) and/or changing the winning rule to connect 3 instead of 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Game Environment and Random Agent [2 point]\n",
    "\n",
    "Use a numpy character array as the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the board and helper functions for:\n",
    "\n",
    "* The transition model (result).\n",
    "* The utility function.\n",
    "* Check for terminal states.\n",
    "* A check for available actions.\n",
    "* A function to visualize the board.\n",
    "\n",
    "Make sure that all these functions work with boards of different sizes.\n",
    "\n",
    "Implement an agent that plays randomly and let two random agents play against each other 1000 times. How often does each player win? Is the result expected? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "def empty_board(shape=(6, 7)):\n",
    "    return np.full(shape=shape, fill_value=' ')\n",
    "\n",
    "def show_board(board):\n",
    "    for row in board:\n",
    "        line = '|'\n",
    "        for char in row:\n",
    "            line += char +  '|'\n",
    "        print(line)\n",
    "    print('_' * (2*len(board[0]) + 1))\n",
    "show_board(empty_board())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of colors for the players use 'x' and 'o' to represent the players. Make sure that your agent functions all have the from: `agent_type(board, player = 'x')`, where board is the current board position and player is the player whose next move it is and who the agent should play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def to_move(board, player, move):\n",
    "    new_board = board.copy()\n",
    "    for row in reversed(new_board):\n",
    "        if row[move] == ' ':\n",
    "            row[move] = player\n",
    "            return new_board\n",
    "    return board\n",
    "#helper for utility functions\n",
    "def diagonal_rows(arr):\n",
    "    rows = []\n",
    "    num_rows = len(arr)\n",
    "    num_cols = len(arr[0])\n",
    "    arr = np.asarray(arr)\n",
    "    arr2 = arr.copy()\n",
    "    arr2 = np.fliplr(arr2)\n",
    "    for i in range((-1)*max(num_cols,num_rows),max(num_cols,num_rows)):\n",
    "        possible_arr = np.diagonal(arr,i,axis1=0,axis2=1)\n",
    "        if len(possible_arr) != 0:\n",
    "            rows.append(possible_arr)\n",
    "        possible_arr = np.diagonal(arr2,i,axis1=0,axis2=1)\n",
    "        if len(possible_arr) != 0:\n",
    "            rows.append(possible_arr)\n",
    "    return rows\n",
    "def switch_player(player):\n",
    "    if player == 'x':\n",
    "        return 'o'\n",
    "    else:\n",
    "        return 'x'\n",
    "\n",
    "def utility(board, player):\n",
    "    opponent = switch_player(player)\n",
    "    #check if there is a horizonatal winner\n",
    "    for row in board:\n",
    "        for x in range(0, len(row) - 3):\n",
    "            if row[x] == player and row[x + 1] == player and row[x + 2] == player and row[x + 3] == player:\n",
    "                return 1\n",
    "            if row[x] == opponent and row[x + 1] == opponent and row[x + 2] == opponent and row[x + 3] == opponent:\n",
    "                return -1\n",
    "    #check if there is a vertical winner\n",
    "    vertical_board = board.copy()\n",
    "    vertical_board = np.rot90(vertical_board)\n",
    "    for row in vertical_board:\n",
    "        for x in range(0, len(row) - 3):\n",
    "            if row[x] == player and row[x + 1] == player and row[x + 2] == player and row[x + 3] == player:\n",
    "                return 1\n",
    "            if row[x] == opponent and row[x + 1] == opponent and row[x + 2] == opponent and row[x + 3] == opponent:\n",
    "                return -1\n",
    "    rows = len(board)\n",
    "    columns = len(board[0])\n",
    "    #check diagonal\n",
    "    for row in diagonal_rows(board):\n",
    "        for x in range(0, len(row) - 3):\n",
    "            if row[x] == player and row[x + 1] == player and row[x + 2] == player and row[x + 3] == player:\n",
    "                return 1\n",
    "            if row[x] == opponent and row[x + 1] == opponent and row[x + 2] == opponent and row[x + 3] == opponent:\n",
    "                return -1\n",
    "    if len(actions(board))==0:\n",
    "        return 0\n",
    "    return None\n",
    "\n",
    "def actions(board):\n",
    "    options = []\n",
    "    for i in range(0,len(board[0])):\n",
    "        if board[0][i] == ' ':\n",
    "            options.append(i)\n",
    "    return options\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "class random_agent:\n",
    "    def __init__(self,character):\n",
    "        self.character = character\n",
    "    \n",
    "    def act(self, board):\n",
    "        moves = actions(board)\n",
    "        move_int = rand.choice(moves)\n",
    "        return to_move(board, self.character,move_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|x| | | | | | |\n",
      "_______________\n",
      "None\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|x| | | | | | |\n",
      "|x| | | | | | |\n",
      "|x| | | | | | |\n",
      "|x| | | | | | |\n",
      "_______________\n",
      "1\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|x| | | | | | |\n",
      "|x| | | | | | |\n",
      "|x|o|o|o|o| | |\n",
      "_______________\n",
      "-1\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | |x| | | |\n",
      "|x| |x|o| | | |\n",
      "|x|x|o|o| | | |\n",
      "|x|o|o|o| | | |\n",
      "_______________\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Testing some of these functions\n",
    "\n",
    "\n",
    "board = empty_board()\n",
    "show_board(board)\n",
    "board = to_move(board,'x',0)\n",
    "show_board(board)\n",
    "print(utility(board,'x'))\n",
    "board = to_move(board,'x',0)\n",
    "board = to_move(board,'x',0)\n",
    "board2 = to_move(board,'x',0)\n",
    "show_board(board2)\n",
    "print(utility(board2,'x'))\n",
    "\n",
    "\n",
    "board = to_move(board,'o',1)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'o',3)\n",
    "board3 = to_move(board,'o',4)\n",
    "show_board(board3)\n",
    "print(utility(board3,'x'))\n",
    "\n",
    "board = to_move(board,'x',1)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',3)\n",
    "board = to_move(board,'o',3)\n",
    "board4 = to_move(board,'x',3)\n",
    "show_board(board4)\n",
    "print(utility(board4,'x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_randoms(n,shape=(6,7),print_boards=False):\n",
    "    x_wins = 0\n",
    "    o_wins = 0\n",
    "    draws = 0\n",
    "    for i in range(0,n):\n",
    "        board = empty_board(shape=shape)\n",
    "        agent1 = random_agent('x')\n",
    "        agent2 = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = agent1.act(board)\n",
    "            if utility(board, agent1.character) == 1:\n",
    "                winner = agent1.character\n",
    "                x_wins = x_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = agent2.act(board)\n",
    "            if utility(board, agent2.character) == 1:\n",
    "                winner = agent2.character\n",
    "                o_wins = o_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            print(board)\n",
    "    return (x_wins, o_wins, draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5533, 4447, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_randoms(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3: Minimax Search with Alpha-Beta Pruning [4 points]\n",
    "\n",
    "### Implement the search starting from a given board and specifying the player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEBUG = 1 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "\n",
    "def alpha_beta_search(board, player = 'x'):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    \n",
    "    value, move = max_value_ab(board, player, -math.inf, +math.inf)\n",
    "    \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched: {COUNT}\") \n",
    "    \n",
    "    return value, move\n",
    "\n",
    "def max_value_ab(state, player, alpha, beta):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "       \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"max: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "        \n",
    "    v, move = -math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = min_value_ab(to_move(state, player, a), player, alpha, beta)\n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta: return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def min_value_ab(state, player, alpha, beta):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"min: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = max_value_ab(to_move(state, switch_player(player), a), player, alpha, beta)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        if v <= alpha: return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes searched: 62889\n",
      "Wall time: 5.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((4,4))\n",
    "move = alpha_beta_search(board, player = 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with some manually created boards (at least 5) to check if the agent spots wining opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|o|o|o| | |\n",
      "|o|o|o| |x|\n",
      "|x|x|x| |o|\n",
      "|o|o|o| |o|\n",
      "|x|x|x| |o|\n",
      "___________\n",
      "Number of nodes searched: 10\n",
      "(1, 3)\n",
      "|o|o|o| | |\n",
      "|o|o|o| |x|\n",
      "|x|x|x| |o|\n",
      "|o|o|o| |o|\n",
      "|x|x|x|x|o|\n",
      "___________\n",
      "Number of nodes searched: 1\n",
      "(-1, None)\n",
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'x'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'o'\n",
    "board[3][2] = 'o'\n",
    "board[2][0] = 'x'\n",
    "board[2][1] = 'x'\n",
    "board[2][2] = 'x'\n",
    "board[1][0] = 'o'\n",
    "board[1][1] = 'o'\n",
    "board[1][2] = 'o'\n",
    "board[0][0] = 'o'\n",
    "board[0][1] = 'o'\n",
    "board[0][2] = 'o'\n",
    "board[4][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "board[1][4] = 'x'\n",
    "show_board(board)\n",
    "move = alpha_beta_search(board, player = 'o')\n",
    "print(move)\n",
    "board = to_move(board,'x',move[1])\n",
    "show_board(board)\n",
    "move = alpha_beta_search(board, player = 'o')\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | |\n",
      "| | | | | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Number of nodes searched: 24203\n",
      "| | | | | |\n",
      "|o| | | | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'o'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'o'\n",
    "board[3][2] = 'x'\n",
    "board[2][0] = 'x'\n",
    "board[2][1] = 'x'\n",
    "board[2][2] = 'o'\n",
    "board[4][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "show_board(board)\n",
    "move = alpha_beta_search(board, player = 'o')\n",
    "board = to_move(board, 'o', move[1])\n",
    "show_board(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something looks off about 'o's move.  We are going to investigate this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting board\n",
      "| | | | | |\n",
      "| | | | | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Number of nodes searched: 24203\n",
      "o moves in space 0\n",
      "Number of nodes searched: 23716\n",
      "x moves in space 0\n",
      "Number of nodes searched: 1613\n",
      "o moves in space 2\n",
      "Number of nodes searched: 291\n",
      "x moves in space 1\n",
      "Number of nodes searched: 76\n",
      "o moves in space 1\n",
      "Number of nodes searched: 41\n",
      "x moves in space 2\n",
      "Number of nodes searched: 14\n",
      "o moves in space 3\n",
      "Number of nodes searched: 12\n",
      "x moves in space 3\n",
      "Number of nodes searched: 3\n",
      "o moves in space 3\n",
      "o has won the game\n",
      "|x|o|x| | |\n",
      "|o|x|o| | |\n",
      "|x|x|o|o|o|\n",
      "|o|o|x|x|o|\n",
      "|x|x|o|o|o|\n",
      "___________\n",
      "Wall time: 6.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'o'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'o'\n",
    "board[3][2] = 'x'\n",
    "board[2][0] = 'x'\n",
    "board[2][1] = 'x'\n",
    "board[2][2] = 'o'\n",
    "board[4][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "def finish_game_ab(board, start_player,show_all_boards=True):\n",
    "    player = start_player\n",
    "    end_game = utility(board, player) != None\n",
    "    game_board = board.copy()\n",
    "    print('Starting board')\n",
    "    show_board(game_board)\n",
    "    while end_game == False:\n",
    "        move = alpha_beta_search(game_board, player = player)\n",
    "        print(player, 'moves in space', move[1])\n",
    "        game_board = to_move(game_board,player, move[1])\n",
    "        if show_all_boards: show_board(game_board)\n",
    "        end_game = utility(game_board, player) != None\n",
    "        if end_game:\n",
    "            print(player, 'has won the game')\n",
    "            if not show_all_boards: show_board(game_board)\n",
    "        player = switch_player(player)\n",
    "finish_game_ab(board,'o',show_all_boards=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It still won in the end.  We are going to do some other tests.  The problem we are experiencing with MiniMax is MiniMax is a depth first search, and does not find the fastest solution, but a solution might be to change the move ordering to check if there is a winning in the array of possible moves.  In the end I conjecture this will only save one layer of lookup, but in a case like this it is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting board\n",
      "| | |x| | |\n",
      "| | |o| | |\n",
      "| | |x| | |\n",
      "| |x|o|o| |\n",
      "| |o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 88962\n",
      "o moves in space 1\n",
      "| | |x| | |\n",
      "| | |o| | |\n",
      "| |o|x| | |\n",
      "| |x|o|o| |\n",
      "| |o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 48493\n",
      "x moves in space 0\n",
      "| | |x| | |\n",
      "| | |o| | |\n",
      "| |o|x| | |\n",
      "| |x|o|o| |\n",
      "|x|o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 5332\n",
      "o moves in space 1\n",
      "| | |x| | |\n",
      "| |o|o| | |\n",
      "| |o|x| | |\n",
      "| |x|o|o| |\n",
      "|x|o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 2775\n",
      "x moves in space 0\n",
      "| | |x| | |\n",
      "| |o|o| | |\n",
      "| |o|x| | |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 769\n",
      "o moves in space 1\n",
      "| |o|x| | |\n",
      "| |o|o| | |\n",
      "| |o|x| | |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 294\n",
      "x moves in space 0\n",
      "| |o|x| | |\n",
      "| |o|o| | |\n",
      "|x|o|x| | |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 52\n",
      "o moves in space 0\n",
      "| |o|x| | |\n",
      "|o|o|o| | |\n",
      "|x|o|x| | |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 47\n",
      "x moves in space 0\n",
      "|x|o|x| | |\n",
      "|o|o|o| | |\n",
      "|x|o|x| | |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 22\n",
      "o moves in space 4\n",
      "|x|o|x| | |\n",
      "|o|o|o| | |\n",
      "|x|o|x| | |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x|o|\n",
      "___________\n",
      "Number of nodes searched: 19\n",
      "x moves in space 3\n",
      "|x|o|x| | |\n",
      "|o|o|o| | |\n",
      "|x|o|x|x| |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x|o|\n",
      "___________\n",
      "Number of nodes searched: 4\n",
      "o moves in space 3\n",
      "|x|o|x| | |\n",
      "|o|o|o|o| |\n",
      "|x|o|x|x| |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x|o|\n",
      "___________\n",
      "o has won the game\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Here is a bigger example, granted we filled in quite a few nodes, but this board is more like \n",
    "#the real board the algorithm will have to compete in.\n",
    "board = empty_board((5,5))\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',1)\n",
    "board = to_move(board,'x',3)\n",
    "board = to_move(board,'o',3)\n",
    "board = to_move(board,'x',1)\n",
    "finish_game_ab(board,'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move ordering\n",
    "\n",
    "Describe and implement a simple move ordering strategy. How does this strategy influence the time it takes to \n",
    "make a move?\n",
    "So that we can test multiple move ordering we are going to redo the search fucntion to take a paramter for which function to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def ordering_original(board, player):\n",
    "    options = []\n",
    "    for i in range(0,len(board[0])):\n",
    "        if board[0][i] == ' ':\n",
    "            options.append(i)\n",
    "    return options\n",
    "def ordering_middle(board, player):\n",
    "    options_orig = ordering_original(board, player)\n",
    "    options = []\n",
    "    num_cols = len(board[0]) \n",
    "    if num_cols // 2 in options_orig:\n",
    "        options.append(num_cols // 2)\n",
    "    for i in range(1, (num_cols // 2) + 1):\n",
    "        if (num_cols // 2 - i) in options_orig:\n",
    "            options.append(num_cols // 2 - i)\n",
    "        if (num_cols // 2 + i) in options_orig:\n",
    "            options.append(num_cols // 2 + i)\n",
    "    return options\n",
    "def ordering_middle_reverse(board, player):\n",
    "    return ordering_middle(board, player)[::-1]\n",
    "def ordering_random(board, player):\n",
    "    options = ordering_original(board, player)\n",
    "    random.shuffle(options)\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5]\n",
      "[3, 2, 4, 1, 5, 0]\n",
      "[0, 5, 1, 4, 2, 3]\n",
      "[0, 3, 5, 2, 1, 4]\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "[3, 2, 4, 1, 5, 0, 6]\n",
      "[6, 0, 5, 1, 4, 2, 3]\n",
      "[4, 3, 0, 2, 1, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "board = empty_board(shape=(6,6))\n",
    "print(ordering_original(board,'x'))\n",
    "print(ordering_middle(board,'x'))\n",
    "print(ordering_middle_reverse(board,'x'))\n",
    "print(ordering_random(board,'x'))\n",
    "board = empty_board(shape=(6,7))\n",
    "print(ordering_original(board,'x'))\n",
    "print(ordering_middle(board,'x'))\n",
    "print(ordering_middle_reverse(board,'x'))\n",
    "print(ordering_random(board,'x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEBUG = 1 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "def alpha_beta_search_ordering(board, player = 'x', ordering=ordering_original):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    \n",
    "    value, move = max_value_ab_ordering(board, player,ordering, -math.inf, +math.inf)\n",
    "    \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched {ordering.__name__}: {COUNT}\") \n",
    "    \n",
    "    return value, move\n",
    "\n",
    "def max_value_ab_ordering(state, player,ordering, alpha, beta):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "       \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"max: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "        \n",
    "    v, move = -math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in ordering(state,player):\n",
    "        v2, a2 = min_value_ab_ordering(to_move(state, player, a), player,ordering, alpha, beta)\n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta: return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def min_value_ab_ordering(state, player,ordering, alpha, beta):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"min: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in ordering(state,switch_player(player)):\n",
    "        v2, a2 = max_value_ab_ordering(to_move(state, switch_player(player), a), player,ordering, alpha, beta)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        if v <= alpha: return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | |\n",
      "| | | | |x|\n",
      "|x| | | |o|\n",
      "|o|x|o| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Number of nodes searched ordering_original: 22235\n",
      "(1, 2)\n",
      "Number of nodes searched ordering_middle: 7412\n",
      "(1, 2)\n",
      "Number of nodes searched ordering_middle_reverse: 482105\n",
      "(1, 2)\n",
      "Number of nodes searched ordering_random: 25151\n",
      "(1, 2)\n",
      "Number of nodes searched ordering_random: 43232\n",
      "(1, 2)\n",
      "Number of nodes searched ordering_random: 42368\n",
      "(1, 2)\n",
      "Number of nodes searched ordering_random: 29833\n",
      "(1, 2)\n",
      "Number of nodes searched ordering_random: 50614\n",
      "(1, 2)\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'o'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'x'\n",
    "board[3][2] = 'o'\n",
    "board[2][0] = 'x'\n",
    "board[4][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "board[1][4] = 'x'\n",
    "show_board(board)\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_original))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_middle))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_middle_reverse))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_random))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_random))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_random))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_random))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something truly interesting about this run of data is the comparison between the middle ordering and the reverse middle ordering.  This seems to be the best compared to the worst, and what is common with most games.  Futher than this I think we can add a little bit to the middle out ordering to perform just a little bit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 3, 0, 4]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ordering_middle_winner(board, player):\n",
    "    orders_middle = ordering_middle(board,player)\n",
    "    ordering_won = []\n",
    "    ordering_lost = []\n",
    "    ordering_none = []\n",
    "    for o in orders_middle:\n",
    "        new_board = to_move(board,player,o)\n",
    "        util = utility(board, player)\n",
    "        if util == 1:\n",
    "            ordering_won.append(o)\n",
    "        elif util == -1:\n",
    "            ordering_lost.append(o)\n",
    "        else:\n",
    "            ordering_none.append(o)\n",
    "    return ordering_won + ordering_none + ordering_lost\n",
    "ordering_middle_winner(board, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | |\n",
      "| | | | | |\n",
      "| | | | | |\n",
      "| | | | | |\n",
      "___________\n",
      "Number of nodes searched ordering_middle: 7692028\n",
      "(0, 2)\n",
      "Number of nodes searched ordering_middle_winner: 7692028\n",
      "(0, 2)\n",
      "Wall time: 45min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((4,5))\n",
    "show_board(board)\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_middle))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_middle_winner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class alpha_beta_search_ordering_agent:\n",
    "    def __init__(self,character, ordering):\n",
    "        self.character = character\n",
    "        self.ordering = ordering\n",
    "    \n",
    "    def act(self, board):\n",
    "        win, move_int = alpha_beta_search_ordering(board, self.character, self.ordering)\n",
    "        return to_move(board, self.character,move_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "global DEBUG\n",
    "DEBUG = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36mplay_vs_random\u001b[1;34m(N, shape, print_boards)\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-b0ad61214f46>\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, board)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mwin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove_int\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha_beta_search_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharacter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharacter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmove_int\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36malpha_beta_search_ordering\u001b[1;34m(board, player, ordering)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mCOUNT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Number of nodes searched {ordering.__name__}: {COUNT}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmax_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmin_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmax_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmin_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmax_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmin_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmax_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmin_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmax_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmin_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmax_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmin_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmax_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmin_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmax_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-244f6da6871a>\u001b[0m in \u001b[0;36mmin_value_ab_ordering\u001b[1;34m(state, player, ordering, alpha, beta)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-86c419e95300>\u001b[0m in \u001b[0;36mto_move\u001b[1;34m(board, player, move)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mnew_board\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def play_vs_random(N=1000, shape=(4,4), print_boards=False):\n",
    "    mini_char = 'o'\n",
    "    random_char = 'x'\n",
    "    mini_wins = 0\n",
    "    random_wins = 0\n",
    "    draws = 0\n",
    "    for i in range(0,N):\n",
    "        board = empty_board(shape=shape)\n",
    "        alpha_beta_agent = alpha_beta_search_ordering_agent('x',ordering_middle)\n",
    "        rand_agent = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = alpha_beta_agent.act(board)\n",
    "            if utility(board, alpha_beta_agent.character) == 1:\n",
    "                winner = alpha_beta_agent.character\n",
    "                mini_wins = mini_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = rand_agent.act(board)\n",
    "            if utility(board, rand_agent.character) == 1:\n",
    "                winner = rand_agent.character\n",
    "                random_wins = random_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            show_board(board)\n",
    "        \n",
    "        #switch who goes first \n",
    "        board = empty_board(shape=shape)\n",
    "        alpha_beta_agent = alpha_beta_search_ordering_agent('x',ordering_middle)\n",
    "        rand_agent = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = rand_agent.act(board)\n",
    "            if utility(board, rand_agent.character) == 1:\n",
    "                winner = rand_agent.character\n",
    "                random_wins = random_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = alpha_beta_agent.act(board)\n",
    "            if utility(board, alpha_beta_agent.character) == 1:\n",
    "                winner = alpha_beta_agent.character\n",
    "                mini_wins = mini_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            show_board(board)\n",
    "    return (mini_wins, random_wins, draws)\n",
    "            \n",
    "play_vs_random(N=1, shape=(4,4),print_boards=False)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(148, 0, 97)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "play_vs_random(N=100, shape=(4,4),print_boards=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search [3 points] \n",
    "\n",
    "### Heuristic evaluation function\n",
    "\n",
    "Define and implement a heuristic evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def score_board(board, player):\n",
    "    #check if there is a horizonatal winner\n",
    "    num_ones_total = 0\n",
    "    num_twos_total = 0\n",
    "    num_threes_total = 0\n",
    "    num_fours_total = 0\n",
    "    for row in board:\n",
    "        num_ones, num_twos, num_threes,num_fours = score_array(row, player)\n",
    "        num_ones_total += num_ones\n",
    "        num_twos_total += num_twos\n",
    "        num_threes_total += num_threes\n",
    "        num_fours_total += num_fours\n",
    "    #print(num_ones_total, num_twos_total, num_threes_total)    \n",
    "    #check if there is a vertical winner\n",
    "    vertical_board = board.copy()\n",
    "    vertical_board = np.rot90(vertical_board)\n",
    "    for row in vertical_board:\n",
    "        num_ones, num_twos, num_threes,num_fours = score_array(row, player)\n",
    "        num_twos_total += num_twos\n",
    "        num_threes_total += num_threes\n",
    "        num_fours_total += num_fours\n",
    "    #print(num_ones_total, num_twos_total, num_threes_total)    \n",
    "\n",
    "    for i in diagonal_rows(board):\n",
    "        num_ones, num_twos, num_threes,num_fours = score_array(i, player)\n",
    "        num_twos_total += num_twos\n",
    "        num_threes_total += num_threes\n",
    "        num_fours_total += num_fours\n",
    "    #print(num_ones_total,num_twos_total,num_threes_total)\n",
    "    #print(num_ones_total, num_twos_total, num_threes_total)    \n",
    "\n",
    "    if num_fours_total > 0:\n",
    "        return 4000, True\n",
    "    return num_twos_total*2 + num_threes_total*100 + num_fours_total*10000, num_fours_total>0\n",
    "\n",
    "def score_array(array, player):\n",
    "    arr = array.copy()\n",
    "    arr = np.insert(arr,obj=0,values=['*'])\n",
    "    arr = np.insert(arr,obj=0,values=['*'])\n",
    "    arr = np.insert(arr,obj=len(arr),values=['*'])\n",
    "    arr = np.insert(arr,obj=len(arr),values=['*'])\n",
    "    \n",
    "    num_ones = 0\n",
    "    num_twos = 0\n",
    "    num_threes = 0\n",
    "    num_fours = 0\n",
    "    current_run = 0\n",
    "    start_char = array[0]\n",
    "    for idx in range(1,len(arr)-1):\n",
    "        c = arr[idx]\n",
    "        if c == player:\n",
    "            current_run += 1\n",
    "        else: \n",
    "            end_char = arr[idx]\n",
    "            if current_run == 1 and (arr[idx] == ' '  or arr[idx-2] == ' ' ):\n",
    "                num_ones += 1\n",
    "            elif current_run == 2 and (arr[idx] == ' '  or arr[idx-3] == ' ' ):\n",
    "                num_twos += 1\n",
    "            elif current_run == 3 and (arr[idx] == ' '  or arr[idx-4] == ' ' ):\n",
    "                num_threes +=1\n",
    "            elif current_run >= 4 and (arr[idx] == ' '  or arr[idx-5] == ' ' ):\n",
    "                num_fours = 1\n",
    "            current_run = 0\n",
    "            start_char = c\n",
    "    return (num_ones,num_twos,num_threes,num_fours)\n",
    "\n",
    "def eval_fun(board, player):\n",
    "    player_score =  score_board(board, player)\n",
    "    oppo_score = score_board(board, switch_player(player))\n",
    "    return player_score[0] - oppo_score[0], player_score[1] or oppo_score[1]\n",
    "def eval_fun_util(board, player):\n",
    "    util = utility(board,player)\n",
    "    if util is None: util = 0\n",
    "    return util, util != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | |\n",
      "| | | | |o|\n",
      "|x|o| | |o|\n",
      "|o|x|o| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3998, True)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'o'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'x'\n",
    "board[3][2] = 'o'\n",
    "board[2][0] = 'x'\n",
    "board[4][4] = 'o'\n",
    "board[1][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "board[2][1] = 'o'\n",
    "show_board(board)\n",
    "eval_fun(board,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEBUG = 2 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "\n",
    "def alpha_beta_search_heuristic(board, \n",
    "                                cutoff = None, fp=None,\n",
    "                                ordering=ordering_middle,\n",
    "                                eval_fun=utility, \n",
    "                                player = 'x'):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    print('I think I am here')\n",
    "    value, move = max_value_ab_heuristic(board, player, ordering,eval_fun,-math.inf, +math.inf, 0, cutoff,fp)\n",
    "    \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched (cutoff = {cutoff}): {COUNT}\") \n",
    "    \n",
    "    return value, move\n",
    "\n",
    "def max_value_ab_heuristic(state, player,ordering,eval_fun, alpha, beta, depth, cutoff,fp):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # cut off and terminal test\n",
    "    v, terminal = eval_fun(state, player)\n",
    "    if((cutoff is not None and depth >= cutoff) or terminal): \n",
    "        if(terminal): alpha, beta = v, v\n",
    "        if DEBUG >= 2: print(f\"stopped at {depth}: {state} term: {terminal} eval: {v} [{alpha}, {beta}]\" ) \n",
    "        return v, None\n",
    "    \n",
    "    v, move = -math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = min_value_ab_heuristic(to_move(state, player, a), player,ordering,eval_fun,alpha, beta, depth + 1, cutoff,fp)\n",
    "        if v2 > v and (fp is None or v2 > fp):\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta: return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def min_value_ab_heuristic(state, player,ordering,eval_fun, alpha, beta, depth, cutoff,fp):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # cut off and terminal test\n",
    "    v, terminal = eval_fun(state, player)\n",
    "    #if((cutoff is not None and depth >= cutoff) or terminal): \n",
    "    # always let the opponent make her move\n",
    "    if(terminal): \n",
    "        if(terminal): alpha, beta = v, v\n",
    "        if DEBUG >= 2: print(f\"stopped at {depth}: {state} term: {terminal} eval: {v} [{alpha}, {beta}]\" ) \n",
    "        return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = max_value_ab_heuristic(to_move(state, switch_player(player), a), player, ordering,eval_fun,alpha, beta, depth + 1, cutoff,fp)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        if v <= alpha: return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|x| | | | |\n",
      "|x| | | | |\n",
      "|x| | | |o|\n",
      "|o|x|o| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "(102, False)\n",
      "(4, False)\n",
      "I think I am here\n",
      "Number of nodes searched (cutoff = 10): 17902\n",
      "(-2, 4)\n",
      "I think I am here\n",
      "Number of nodes searched (cutoff = 10): 10427\n",
      "(3998, 2)\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'o'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'x'\n",
    "board[3][2] = 'o'\n",
    "board[2][0] = 'x'\n",
    "#board[1][4] = 'o'\n",
    "board[4][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "board[1][0] = 'x'\n",
    "board[0][0] = 'x'\n",
    "show_board(board)\n",
    "print(score_board(board, 'o'))\n",
    "print(score_board(board, 'x'))\n",
    "print(alpha_beta_search_heuristic(board, player = 'x', cutoff=10,ordering=eval_fun,eval_fun=eval_fun))\n",
    "print(alpha_beta_search_heuristic(board, player = 'o', cutoff=10, ordering=eval_fun,eval_fun=eval_fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "class alpha_beta_search_ordering_hue_agent:\n",
    "    def __init__(self,character, ordering,evalfun,cutoff,fp):\n",
    "        self.character = character\n",
    "        self.ordering = ordering\n",
    "        self.eval_fun = evalfun\n",
    "        self.cutoff = cutoff\n",
    "        self.fp = fp\n",
    "    def act(self, board):\n",
    "        win, move_int = alpha_beta_search_heuristic(board, \n",
    "                                                    player=self.character, \n",
    "                                                    ordering=self.ordering,\n",
    "                                                    eval_fun=self.eval_fun,\n",
    "                                                    cutoff=self.cutoff,\n",
    "                                                    fp=self.fp)\n",
    "        return to_move(board, self.character,move_int)\n",
    "test = alpha_beta_search_ordering_hue_agent('x',ordering_middle,eval_fun,5,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting off search \n",
    "\n",
    "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n",
      "I think I am here\n",
      "Number of nodes searched (cutoff = 4): 173\n",
      "(0, 0)\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global DEBUG\n",
    "DEBUG = 1\n",
    "board = empty_board((6,7))\n",
    "show_board(board)\n",
    "print(alpha_beta_search_heuristic(board, player='x', cutoff=4, ordering=ordering_original, \n",
    "                                  eval_fun=eval_fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n",
      "I think I am here\n",
      "Number of nodes searched (cutoff = 5): 4285\n",
      "(0, 3)\n",
      "Wall time: 27.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global DEBUG\n",
    "DEBUG = 1\n",
    "board = empty_board((6,7))\n",
    "show_board(board)\n",
    "print(alpha_beta_search_heuristic(board, player='x', cutoff=5, ordering=ordering_original, \n",
    "                                  eval_fun=eval_fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without more analysis we are going to take this test and claim that 5 is a good cutoff.  The reason fo this is because the search was able to find what we \"think\" is the best move on a blank board.  That is the 4th column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with the same manually created boards as above to check if the agent spots wining opportunities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pruning\n",
    "\n",
    "Add forward pruning to the cutoff search where you do not consider moves that have a low evaluation value after a shallow search \n",
    "(way smaller than the cuttoff value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function or different forward pruning) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge task [+ 1 bonus point]\n",
    "\n",
    "Find another student and let your best agent play against the other student's best player. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [1 point]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+1 Bonus point].\n",
    "\n",
    "### Pure Monte Carlos Search\n",
    "\n",
    "Implement Pure Monte Carlo Search and investigate how this search performs on the test boards that you have used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global DEBUG\n",
    "DEBUG = 0\n",
    "def playout(state, action, player = 'x'):\n",
    "    \"\"\"Perfrom a random playout starting with the given action on the fiven board \n",
    "    and return the utility of the finished game.\"\"\"\n",
    "    state = to_move(state, player, action)\n",
    "    current_player = switch_player(player)\n",
    "    \n",
    "    while(True):\n",
    "        # reached terminal state?\n",
    "        u = utility(state, player)\n",
    "        if u is not None: return(u)\n",
    "        \n",
    "        # we use a random playout policy\n",
    "        a = np.random.choice(actions(state))\n",
    "        state = to_move(state, current_player, a)\n",
    "        #print(state)\n",
    "        \n",
    "        # switch between players\n",
    "        current_player = switch_player(current_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playouts(board, action, player = 'x', N = 100):\n",
    "    \"\"\"Perform N playouts following the given action for the given board.\"\"\"\n",
    "    return [ playout(board, action, player) for i in range(N) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmcs(board, N = 100, player = 'x'):\n",
    "    \"\"\"Pure Monte Carlo Search. Returns the action that has the largest average utility.\n",
    "    The N playouts are evenly divided between the possible actions.\"\"\"\n",
    "    global DEBUG\n",
    "    \n",
    "    avail_actions = actions(board)\n",
    "    n = math.floor(N/len(avail_actions))\n",
    "    if DEBUG >= 1: print(f\"Actions: {avail_actions} ({n} playouts per actions)\")\n",
    "    \n",
    "    ps = { i:np.mean(playouts(board, i, player, N = n)) for i in avail_actions }\n",
    "    if DEBUG >= 1: display(ps)\n",
    "        \n",
    "    action = max(ps, key=ps.get)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class monte_agent:\n",
    "    def __init__(self,character, N):\n",
    "        self.character = character\n",
    "        self.N = N\n",
    "    \n",
    "    def act(self, board):\n",
    "        move = pmcs(board, self.N, self.character)\n",
    "        return to_move(board, self.character, move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|o|x| | | | | |\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|o| | | | | | |\n",
      "|o|x| | | |x| |\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|x| | | | | | |\n",
      "|o| | | | | | |\n",
      "|o|x|o| | |x| |\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|x| | | | | | |\n",
      "|o| | | | | | |\n",
      "|o|x|o|o|x|x| |\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|x| | |o| | | |\n",
      "|o| | |x| | | |\n",
      "|o|x|o|o|x|x| |\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|x| | |o| | | |\n",
      "|o|x| |x| |o| |\n",
      "|o|x|o|o|x|x| |\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | |x| | | |\n",
      "|x| | |o| | | |\n",
      "|o|x| |x| |o| |\n",
      "|o|x|o|o|x|x|o|\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | |x| | | |\n",
      "|x|x| |o| |o| |\n",
      "|o|x| |x| |o| |\n",
      "|o|x|o|o|x|x|o|\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | |o| | | |\n",
      "| |x| |x| | | |\n",
      "|x|x| |o| |o| |\n",
      "|o|x| |x| |o| |\n",
      "|o|x|o|o|x|x|o|\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "monte = monte_agent('x', 100)\n",
    "random = random_agent('o')\n",
    "board = empty_board() \n",
    "show_board(board)\n",
    "winner = False\n",
    "while(len(actions(board)) != 0 and not winner):\n",
    "    board = monte.act(board)\n",
    "    board = random.act(board)\n",
    "    winner = utility(board, monte.character) is not None\n",
    "    show_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_vs_monte(N=1000, monte_size=100,shape=(6,7), print_boards=False):\n",
    "    mini_char = 'o'\n",
    "    random_char = 'x'\n",
    "    mini_wins = 0\n",
    "    random_wins = 0\n",
    "    draws = 0\n",
    "    for i in range(0,N):\n",
    "        board = empty_board(shape=shape)\n",
    "        monte = monte_agent('x', monte_size)\n",
    "        rand_agent = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = monte.act(board)\n",
    "            if utility(board, monte.character) == 1:\n",
    "                winner = monte.character\n",
    "                mini_wins = mini_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = rand_agent.act(board)\n",
    "            if utility(board, rand_agent.character) == 1:\n",
    "                winner = rand_agent.character\n",
    "                random_wins = random_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            show_board(board)\n",
    "        \n",
    "        #switch who goes first \n",
    "        board = empty_board(shape=shape)\n",
    "        monte = monte_agent('x', monte_size)\n",
    "        rand_agent = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = rand_agent.act(board)\n",
    "            if utility(board, rand_agent.character) == 1:\n",
    "                winner = rand_agent.character\n",
    "                random_wins = random_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = monte.act(board)\n",
    "            if utility(board, monte.character) == 1:\n",
    "                winner = monte.character\n",
    "                mini_wins = mini_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            show_board(board)\n",
    "    return (mini_wins, random_wins, draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 0, 0)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "play_vs_monte(N=50,monte_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Move\n",
    "\n",
    "How would you determine what the best first move is? You can use Pure Monte Carlo Search or any algorithms \n",
    "that you have implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple I would make the monte carlo search make the first move and give it time till the percentages don't seem to change.\n",
    "def pmcs_full_return(board, N = 100, player = 'x'):\n",
    "    \"\"\"Pure Monte Carlo Search. Returns the action that has the largest average utility.\n",
    "    The N playouts are evenly divided between the possible actions.\"\"\"\n",
    "    \n",
    "    avail_actions = actions(board)\n",
    "    n = math.floor(N/len(avail_actions))\n",
    "    #if DEBUG >= 1: print(f\"Actions: {avail_actions} ({n} playouts per actions)\")\n",
    "    \n",
    "    ps = { i:np.mean(playouts(board, i, player, N = n)) for i in avail_actions }\n",
    "    #if DEBUG >= 1: display(ps)\n",
    "        \n",
    "    action = max(ps, key=ps.get)\n",
    "    return ps\n",
    "\n",
    "board = empty_board()\n",
    "monte_size = 1000\n",
    "last_run = pmcs_full_return(board,monte_size,'x')\n",
    "last_run = last_run.values()\n",
    "last_run = np.array(list(last_run))\n",
    "cont = True\n",
    "runs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-75d050365783>\u001b[0m in \u001b[0;36mpmcs_full_return\u001b[1;34m(board, N, player)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#if DEBUG >= 1: print(f\"Actions: {avail_actions} ({n} playouts per actions)\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mavail_actions\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#if DEBUG >= 1: display(ps)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-75d050365783>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#if DEBUG >= 1: print(f\"Actions: {avail_actions} ({n} playouts per actions)\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mavail_actions\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#if DEBUG >= 1: display(ps)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-555cafd16102>\u001b[0m in \u001b[0;36mplayouts\u001b[1;34m(board, action, player, N)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplayouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Perform N playouts following the given action for the given board.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mplayout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-555cafd16102>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplayouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Perform N playouts following the given action for the given board.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mplayout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-d9e6bd9d57b8>\u001b[0m in \u001b[0;36mplayout\u001b[1;34m(state, action, player)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# reached terminal state?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-86c419e95300>\u001b[0m in \u001b[0;36mutility\u001b[1;34m(board, player)\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m#check if there is a vertical winner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mvertical_board\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mvertical_board\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvertical_board\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvertical_board\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cont = True\n",
    "while cont:\n",
    "    current_run = pmcs_full_return(board,monte_size,'x')\n",
    "    current_run = current_run.values()\n",
    "    current_run = np.array(list(current_run))\n",
    "    norm_diff = np.linalg.norm(last_run - current_run)    \n",
    "    runs.append([monte_size,norm_diff])\n",
    "    if norm_diff < .01:\n",
    "        cont = False\n",
    "    last_run = current_run\n",
    "    monte_size *= 1.1\n",
    "    #print(monte_size, norm_diff)\n",
    "print(last_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.02155081, 0.08398479, 0.16173674, 0.28512571, 0.15244031,\n",
       "       0.07616734, 0.01827593])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = [i[0] for i in runs]\n",
    "y = [i[1] for i in runs]\n",
    "y_bottom = [.01] * len(runs) \n",
    "plt.plot(x,y,x,y_bottom)\n",
    "plt.show()\n",
    "last_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02296886647712697"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72890.48368510327"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
