{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Playing Connect 4\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: Undegraduates 10, graduate students 11\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play Connect 4:\n",
    "\n",
    "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the Search Problem [1 point]\n",
    "\n",
    "Define the components of the search problem:\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model\n",
    "* Goal state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Initial state\n",
    " * Empty board and it is marked as someones turn.\n",
    "* Actions\n",
    " * Either player can play in either column, as long as there isn't 6 pieces in that column.\n",
    "* Transition model\n",
    " * Given a state and an action, the next state is the same board with one more piece on the lowest availble space of the chosen action.\n",
    "* Goal state\n",
    " * Goal States for both players is all states with 4 or more in a diagonal ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the search space?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State space disscussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we start be considering each column we can see that each column can have up to 6 pieces in it.  That would give us 7^6 stated agnostic of color.\n",
    "* Expanding on this we want to know how many states there is if we include color.\n",
    " * A single column of height 1 has 2^1 states.\n",
    "   * 'x' and 'o'\n",
    " * A single column of height 2 has 2^2 states.\n",
    "   * 'xx', 'xo', 'oo', 'ox'\n",
    " * ....\n",
    " * A single column of height 6 has 2^6 states.'\n",
    "* That gives us a state space of:\n",
    "\n",
    "7^(2^1+ 2^2 + 2^3 + 2^3 + 2^5 + 2^6 + 2^7) = 7^126 = 3.036358 * 10^106\n",
    "\n",
    "This is an upper bound because the board might have more than one winner, and thus is unreachable, but it is still a good estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ The search space for a $6 \\times 7$ board is large. You can experiment with smaller boards (the smallest is $4 times \\4$) and/or changing the winning rule to connect 3 instead of 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Game Environment and Random Agent [2 point]\n",
    "\n",
    "Use a numpy character array as the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the board and helper functions for:\n",
    "\n",
    "* The transition model (result).\n",
    "* The utility function.\n",
    "* Check for terminal states.\n",
    "* A check for available actions.\n",
    "* A function to visualize the board.\n",
    "\n",
    "Make sure that all these functions work with boards of different sizes.\n",
    "\n",
    "Implement an agent that plays randomly and let two random agents play against each other 1000 times. How often does each player win? Is the result expected? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "def empty_board(shape=(6, 7)):\n",
    "    return np.full(shape=shape, fill_value=' ')\n",
    "\n",
    "def show_board(board):\n",
    "    for row in board:\n",
    "        line = '|'\n",
    "        for char in row:\n",
    "            line += char +  '|'\n",
    "        print(line)\n",
    "    print('_' * (2*len(board[0]) + 1))\n",
    "show_board(empty_board())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of colors for the players use 'x' and 'o' to represent the players. Make sure that your agent functions all have the from: `agent_type(board, player = 'x')`, where board is the current board position and player is the player whose next move it is and who the agent should play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def to_move(board, player, move):\n",
    "    new_board = board.copy()\n",
    "    for row in reversed(new_board):\n",
    "        if row[move] == ' ':\n",
    "            row[move] = player\n",
    "            return new_board\n",
    "    return board\n",
    "#helper for utility functions\n",
    "def diagonal_rows(arr):\n",
    "    rows = []\n",
    "    num_rows = len(arr)\n",
    "    num_cols = len(arr[0])\n",
    "    arr = np.asarray(arr)\n",
    "    arr2 = arr.copy()\n",
    "    arr2 = np.fliplr(arr2)\n",
    "    for i in range((-1)*max(num_cols,num_rows),max(num_cols,num_rows)):\n",
    "        possible_arr = np.diagonal(arr,i,axis1=0,axis2=1)\n",
    "        if len(possible_arr) != 0:\n",
    "            rows.append(possible_arr)\n",
    "        possible_arr = np.diagonal(arr2,i,axis1=0,axis2=1)\n",
    "        if len(possible_arr) != 0:\n",
    "            rows.append(possible_arr)\n",
    "    return rows\n",
    "def switch_player(player):\n",
    "    if player == 'x':\n",
    "        return 'o'\n",
    "    else:\n",
    "        return 'x'\n",
    "\n",
    "def utility(board, player):\n",
    "    opponent = switch_player(player)\n",
    "    #check if there is a horizonatal winner\n",
    "    for row in board:\n",
    "        for x in range(0, len(row) - 3):\n",
    "            if row[x] == player and row[x + 1] == player and row[x + 2] == player and row[x + 3] == player:\n",
    "                return 1\n",
    "            if row[x] == opponent and row[x + 1] == opponent and row[x + 2] == opponent and row[x + 3] == opponent:\n",
    "                return -1\n",
    "    #check if there is a vertical winner\n",
    "    vertical_board = board.copy()\n",
    "    vertical_board = np.rot90(vertical_board)\n",
    "    for row in vertical_board:\n",
    "        for x in range(0, len(row) - 3):\n",
    "            if row[x] == player and row[x + 1] == player and row[x + 2] == player and row[x + 3] == player:\n",
    "                return 1\n",
    "            if row[x] == opponent and row[x + 1] == opponent and row[x + 2] == opponent and row[x + 3] == opponent:\n",
    "                return -1\n",
    "    rows = len(board)\n",
    "    columns = len(board[0])\n",
    "    #check diagonal\n",
    "    for row in diagonal_rows(board):\n",
    "        for x in range(0, len(row) - 3):\n",
    "            if row[x] == player and row[x + 1] == player and row[x + 2] == player and row[x + 3] == player:\n",
    "                return 1\n",
    "            if row[x] == opponent and row[x + 1] == opponent and row[x + 2] == opponent and row[x + 3] == opponent:\n",
    "                return -1\n",
    "    if len(actions(board))==0:\n",
    "        return 0\n",
    "    return None\n",
    "\n",
    "def actions(board):\n",
    "    options = []\n",
    "    for i in range(0,len(board[0])):\n",
    "        if board[0][i] == ' ':\n",
    "            options.append(i)\n",
    "    return options\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "class random_agent:\n",
    "    def __init__(self,character):\n",
    "        self.character = character\n",
    "    \n",
    "    def act(self, board):\n",
    "        moves = actions(board)\n",
    "        move_int = rand.choice(moves)\n",
    "        return to_move(board, self.character,move_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|x| | | | | | |\n",
      "_______________\n",
      "None\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|x| | | | | | |\n",
      "|x| | | | | | |\n",
      "|x| | | | | | |\n",
      "|x| | | | | | |\n",
      "_______________\n",
      "1\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "|x| | | | | | |\n",
      "|x| | | | | | |\n",
      "|x|o|o|o|o| | |\n",
      "_______________\n",
      "-1\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | |x| | | |\n",
      "|x| |x|o| | | |\n",
      "|x|x|o|o| | | |\n",
      "|x|o|o|o| | | |\n",
      "_______________\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Testing some of these functions\n",
    "\n",
    "\n",
    "board = empty_board()\n",
    "show_board(board)\n",
    "board = to_move(board,'x',0)\n",
    "show_board(board)\n",
    "print(utility(board,'x'))\n",
    "board = to_move(board,'x',0)\n",
    "board = to_move(board,'x',0)\n",
    "board2 = to_move(board,'x',0)\n",
    "show_board(board2)\n",
    "print(utility(board2,'x'))\n",
    "\n",
    "\n",
    "board = to_move(board,'o',1)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'o',3)\n",
    "board3 = to_move(board,'o',4)\n",
    "show_board(board3)\n",
    "print(utility(board3,'x'))\n",
    "\n",
    "board = to_move(board,'x',1)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',3)\n",
    "board = to_move(board,'o',3)\n",
    "board4 = to_move(board,'x',3)\n",
    "show_board(board4)\n",
    "print(utility(board4,'x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_randoms(n,shape=(6,7),print_boards=False):\n",
    "    x_wins = 0\n",
    "    o_wins = 0\n",
    "    draws = 0\n",
    "    for i in range(0,n):\n",
    "        board = empty_board(shape=shape)\n",
    "        agent1 = random_agent('x')\n",
    "        agent2 = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = agent1.act(board)\n",
    "            if utility(board, agent1.character) == 1:\n",
    "                winner = agent1.character\n",
    "                x_wins = x_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = agent2.act(board)\n",
    "            if utility(board, agent2.character) == 1:\n",
    "                winner = agent2.character\n",
    "                o_wins = o_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            print(board)\n",
    "    return (x_wins, o_wins, draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5581, 4390, 38)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_randoms(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3: Minimax Search with Alpha-Beta Pruning [4 points]\n",
    "\n",
    "### Implement the search starting from a given board and specifying the player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEBUG = 1 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "\n",
    "def alpha_beta_search(board, player = 'x'):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    \n",
    "    value, move = max_value_ab(board, player, -math.inf, +math.inf)\n",
    "    \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched: {COUNT}\") \n",
    "    \n",
    "    return value, move\n",
    "\n",
    "def max_value_ab(state, player, alpha, beta):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "       \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"max: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "        \n",
    "    v, move = -math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = min_value_ab(to_move(state, player, a), player, alpha, beta)\n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta: return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def min_value_ab(state, player, alpha, beta):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"min: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = max_value_ab(to_move(state, switch_player(player), a), player, alpha, beta)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        if v <= alpha: return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes searched: 62889\n",
      "Wall time: 5.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((4,4))\n",
    "move = alpha_beta_search(board, player = 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with some manually created boards (at least 5) to check if the agent spots wining opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|o|o|o| | |\n",
      "|o|o|o| |x|\n",
      "|x|x|x| |o|\n",
      "|o|o|o| |o|\n",
      "|x|x|x| |o|\n",
      "___________\n",
      "Number of nodes searched: 10\n",
      "(1, 3)\n",
      "|o|o|o| | |\n",
      "|o|o|o| |x|\n",
      "|x|x|x| |o|\n",
      "|o|o|o| |o|\n",
      "|x|x|x|x|o|\n",
      "___________\n",
      "Number of nodes searched: 1\n",
      "(-1, None)\n",
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'x'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'o'\n",
    "board[3][2] = 'o'\n",
    "board[2][0] = 'x'\n",
    "board[2][1] = 'x'\n",
    "board[2][2] = 'x'\n",
    "board[1][0] = 'o'\n",
    "board[1][1] = 'o'\n",
    "board[1][2] = 'o'\n",
    "board[0][0] = 'o'\n",
    "board[0][1] = 'o'\n",
    "board[0][2] = 'o'\n",
    "board[4][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "board[1][4] = 'x'\n",
    "show_board(board)\n",
    "move = alpha_beta_search(board, player = 'o')\n",
    "print(move)\n",
    "board = to_move(board,'x',move[1])\n",
    "show_board(board)\n",
    "move = alpha_beta_search(board, player = 'o')\n",
    "print(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | |\n",
      "| | | | | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Number of nodes searched: 24203\n",
      "| | | | | |\n",
      "|o| | | | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Wall time: 2.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'o'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'o'\n",
    "board[3][2] = 'x'\n",
    "board[2][0] = 'x'\n",
    "board[2][1] = 'x'\n",
    "board[2][2] = 'o'\n",
    "board[4][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "show_board(board)\n",
    "move = alpha_beta_search(board, player = 'o')\n",
    "board = to_move(board, 'o', move[1])\n",
    "show_board(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something looks off about 'o's move.  We are going to investigate this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting board\n",
      "| | | | | |\n",
      "| | | | | |\n",
      "|x|x|o| |o|\n",
      "|o|o|x| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Number of nodes searched: 24203\n",
      "o moves in space 0\n",
      "Number of nodes searched: 23716\n",
      "x moves in space 0\n",
      "Number of nodes searched: 1613\n",
      "o moves in space 2\n",
      "Number of nodes searched: 291\n",
      "x moves in space 1\n",
      "Number of nodes searched: 76\n",
      "o moves in space 1\n",
      "Number of nodes searched: 41\n",
      "x moves in space 2\n",
      "Number of nodes searched: 14\n",
      "o moves in space 3\n",
      "Number of nodes searched: 12\n",
      "x moves in space 3\n",
      "Number of nodes searched: 3\n",
      "o moves in space 3\n",
      "o has won the game\n",
      "|x|o|x| | |\n",
      "|o|x|o| | |\n",
      "|x|x|o|o|o|\n",
      "|o|o|x|x|o|\n",
      "|x|x|o|o|o|\n",
      "___________\n",
      "Wall time: 5.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'o'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'o'\n",
    "board[3][2] = 'x'\n",
    "board[2][0] = 'x'\n",
    "board[2][1] = 'x'\n",
    "board[2][2] = 'o'\n",
    "board[4][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "def finish_game_ab(board, start_player,show_all_boards=True):\n",
    "    player = start_player\n",
    "    end_game = utility(board, player) != None\n",
    "    game_board = board.copy()\n",
    "    print('Starting board')\n",
    "    show_board(game_board)\n",
    "    while end_game == False:\n",
    "        move = alpha_beta_search(game_board, player = player)\n",
    "        print(player, 'moves in space', move[1])\n",
    "        game_board = to_move(game_board,player, move[1])\n",
    "        if show_all_boards: show_board(game_board)\n",
    "        end_game = utility(game_board, player) != None\n",
    "        if end_game:\n",
    "            print(player, 'has won the game')\n",
    "            if not show_all_boards: show_board(game_board)\n",
    "        player = switch_player(player)\n",
    "finish_game_ab(board,'o',show_all_boards=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It still won in the end.  We are going to do some other tests.  The problem we are experiencing with MiniMax is MiniMax is a depth first search, and does not find the fastest solution, but a solution might be to change the move ordering to check if there is a winning in the array of possible moves.  In the end I conjecture this will only save one layer of lookup, but in a case like this it is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting board\n",
      "| | |x| | |\n",
      "| | |o| | |\n",
      "| | |x| | |\n",
      "| |x|o|o| |\n",
      "| |o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 88962\n",
      "o moves in space 1\n",
      "| | |x| | |\n",
      "| | |o| | |\n",
      "| |o|x| | |\n",
      "| |x|o|o| |\n",
      "| |o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 48493\n",
      "x moves in space 0\n",
      "| | |x| | |\n",
      "| | |o| | |\n",
      "| |o|x| | |\n",
      "| |x|o|o| |\n",
      "|x|o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 5332\n",
      "o moves in space 1\n",
      "| | |x| | |\n",
      "| |o|o| | |\n",
      "| |o|x| | |\n",
      "| |x|o|o| |\n",
      "|x|o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 2775\n",
      "x moves in space 0\n",
      "| | |x| | |\n",
      "| |o|o| | |\n",
      "| |o|x| | |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 769\n",
      "o moves in space 1\n",
      "| |o|x| | |\n",
      "| |o|o| | |\n",
      "| |o|x| | |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 294\n",
      "x moves in space 0\n",
      "| |o|x| | |\n",
      "| |o|o| | |\n",
      "|x|o|x| | |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 52\n",
      "o moves in space 0\n",
      "| |o|x| | |\n",
      "|o|o|o| | |\n",
      "|x|o|x| | |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 47\n",
      "x moves in space 0\n",
      "|x|o|x| | |\n",
      "|o|o|o| | |\n",
      "|x|o|x| | |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x| |\n",
      "___________\n",
      "Number of nodes searched: 22\n",
      "o moves in space 4\n",
      "|x|o|x| | |\n",
      "|o|o|o| | |\n",
      "|x|o|x| | |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x|o|\n",
      "___________\n",
      "Number of nodes searched: 19\n",
      "x moves in space 3\n",
      "|x|o|x| | |\n",
      "|o|o|o| | |\n",
      "|x|o|x|x| |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x|o|\n",
      "___________\n",
      "Number of nodes searched: 4\n",
      "o moves in space 3\n",
      "|x|o|x| | |\n",
      "|o|o|o|o| |\n",
      "|x|o|x|x| |\n",
      "|x|x|o|o| |\n",
      "|x|o|x|x|o|\n",
      "___________\n",
      "o has won the game\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Here is a bigger example, granted we filled in quite a few nodes, but this board is more like \n",
    "#the real board the algorithm will have to compete in.\n",
    "board = empty_board((5,5))\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',1)\n",
    "board = to_move(board,'x',3)\n",
    "board = to_move(board,'o',3)\n",
    "board = to_move(board,'x',1)\n",
    "finish_game_ab(board,'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move ordering\n",
    "\n",
    "Describe and implement a simple move ordering strategy. How does this strategy influence the time it takes to \n",
    "make a move?\n",
    "So that we can test multiple move ordering we are going to redo the search fucntion to take a paramter for which function to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def ordering_original(board, player):\n",
    "    options = []\n",
    "    for i in range(0,len(board[0])):\n",
    "        if board[0][i] == ' ':\n",
    "            options.append(i)\n",
    "    return options\n",
    "def ordering_middle(board, player):\n",
    "    options_orig = ordering_original(board, player)\n",
    "    options = []\n",
    "    num_cols = len(board[0]) \n",
    "    if num_cols // 2 in options_orig:\n",
    "        options.append(num_cols // 2)\n",
    "    for i in range(1, (num_cols // 2) + 1):\n",
    "        if (num_cols // 2 - i) in options_orig:\n",
    "            options.append(num_cols // 2 - i)\n",
    "        if (num_cols // 2 + i) in options_orig:\n",
    "            options.append(num_cols // 2 + i)\n",
    "    return options\n",
    "def ordering_middle_reverse(board, player):\n",
    "    return ordering_middle(board, player)[::-1]\n",
    "def ordering_random(board, player):\n",
    "    options = ordering_original(board, player)\n",
    "    random.shuffle(options)\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5]\n",
      "[3, 2, 4, 1, 5, 0]\n",
      "[0, 5, 1, 4, 2, 3]\n",
      "[2, 1, 5, 3, 0, 4]\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "[3, 2, 4, 1, 5, 0, 6]\n",
      "[6, 0, 5, 1, 4, 2, 3]\n",
      "[0, 3, 4, 6, 5, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "board = empty_board(shape=(6,6))\n",
    "print(ordering_original(board,'x'))\n",
    "print(ordering_middle(board,'x'))\n",
    "print(ordering_middle_reverse(board,'x'))\n",
    "print(ordering_random(board,'x'))\n",
    "board = empty_board(shape=(6,7))\n",
    "print(ordering_original(board,'x'))\n",
    "print(ordering_middle(board,'x'))\n",
    "print(ordering_middle_reverse(board,'x'))\n",
    "print(ordering_random(board,'x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEBUG = 1 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "def alpha_beta_search_ordering(board, player = 'x', ordering=ordering_original):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    \n",
    "    value, move = max_value_ab_ordering(board, player,ordering, -math.inf, +math.inf)\n",
    "    \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched {ordering.__name__}: {COUNT}\") \n",
    "    \n",
    "    return value, move\n",
    "\n",
    "def max_value_ab_ordering(state, player,ordering, alpha, beta):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "       \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"max: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "        \n",
    "    v, move = -math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in ordering(state,player):\n",
    "        v2, a2 = min_value_ab_ordering(to_move(state, player, a), player,ordering, alpha, beta)\n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta: return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def min_value_ab_ordering(state, player,ordering, alpha, beta):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"min: \" + str(state) + str([alpha, beta, v]) ) \n",
    "    if v is not None: return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in ordering(state,switch_player(player)):\n",
    "        v2, a2 = max_value_ab_ordering(to_move(state, switch_player(player), a), player,ordering, alpha, beta)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        if v <= alpha: return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | |\n",
      "| | | | |x|\n",
      "|x| | | |o|\n",
      "|o|x|o| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "Number of nodes searched ordering_original: 22235\n",
      "(1, 2)\n",
      "Number of nodes searched ordering_middle: 7412\n",
      "(1, 2)\n",
      "Number of nodes searched ordering_middle_reverse: 482105\n",
      "(1, 2)\n",
      "Number of nodes searched ordering_random: 15374\n",
      "(1, 2)\n",
      "Number of nodes searched ordering_random: 57946\n",
      "(1, 2)\n",
      "Number of nodes searched ordering_random: 44750\n",
      "(1, 2)\n",
      "Number of nodes searched ordering_random: 19466\n",
      "(1, 2)\n",
      "Number of nodes searched ordering_random: 40104\n",
      "(1, 2)\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'o'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'x'\n",
    "board[3][2] = 'o'\n",
    "board[2][0] = 'x'\n",
    "board[4][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "board[1][4] = 'x'\n",
    "show_board(board)\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_original))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_middle))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_middle_reverse))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_random))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_random))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_random))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_random))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something truly interesting about this run of data is the comparison between the middle ordering and the reverse middle ordering.  This seems to be the best compared to the worst, and what is common with most games.  Futher than this I think we can add a little bit to the middle out ordering to perform just a little bit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 3, 0, 4]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ordering_middle_winner(board, player):\n",
    "    orders_middle = ordering_middle(board,player)\n",
    "    ordering_won = []\n",
    "    ordering_lost = []\n",
    "    ordering_none = []\n",
    "    for o in orders_middle:\n",
    "        new_board = to_move(board,player,o)\n",
    "        util = utility(board, player)\n",
    "        if util == 1:\n",
    "            ordering_won.append(o)\n",
    "        elif util == -1:\n",
    "            ordering_lost.append(o)\n",
    "        else:\n",
    "            ordering_none.append(o)\n",
    "    return ordering_won + ordering_none + ordering_lost\n",
    "ordering_middle_winner(board, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | |\n",
      "| | | | | |\n",
      "| | | | | |\n",
      "| | | | | |\n",
      "___________\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((4,5))\n",
    "show_board(board)\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_middle))\n",
    "print(alpha_beta_search_ordering(board, player = 'o', ordering=ordering_middle_winner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class alpha_beta_search_ordering_agent:\n",
    "    def __init__(self,character, ordering):\n",
    "        self.character = character\n",
    "        self.ordering = ordering\n",
    "    \n",
    "    def act(self, board):\n",
    "        win, move_int = alpha_beta_search_ordering(board, self.character, self.ordering)\n",
    "        return to_move(board, self.character,move_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "  global DEBUG\n",
    "DEBUG = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes searched ordering_middle: 155968\n",
      "Number of nodes searched ordering_middle: 64961\n",
      "Number of nodes searched ordering_middle: 6795\n",
      "Number of nodes searched ordering_middle: 783\n",
      "Number of nodes searched ordering_middle: 220\n",
      "Number of nodes searched ordering_middle: 33\n",
      "Number of nodes searched ordering_middle: 12\n",
      "Number of nodes searched ordering_middle: 4\n",
      "Number of nodes searched ordering_middle: 73467\n",
      "Number of nodes searched ordering_middle: 5724\n",
      "Number of nodes searched ordering_middle: 1308\n",
      "Number of nodes searched ordering_middle: 228\n",
      "Number of nodes searched ordering_middle: 97\n",
      "Number of nodes searched ordering_middle: 22\n",
      "Number of nodes searched ordering_middle: 5\n",
      "Wall time: 26.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 0, 0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def play_vs_random(N=1000, shape=(4,4), print_boards=False):\n",
    "    mini_char = 'o'\n",
    "    random_char = 'x'\n",
    "    mini_wins = 0\n",
    "    random_wins = 0\n",
    "    draws = 0\n",
    "    for i in range(0,N):\n",
    "        board = empty_board(shape=shape)\n",
    "        alpha_beta_agent = alpha_beta_search_ordering_agent('x',ordering_middle)\n",
    "        rand_agent = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = alpha_beta_agent.act(board)\n",
    "            if utility(board, alpha_beta_agent.character) == 1:\n",
    "                winner = alpha_beta_agent.character\n",
    "                mini_wins = mini_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = rand_agent.act(board)\n",
    "            if utility(board, rand_agent.character) == 1:\n",
    "                winner = rand_agent.character\n",
    "                random_wins = random_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            show_board(board)\n",
    "        \n",
    "        #switch who goes first \n",
    "        board = empty_board(shape=shape)\n",
    "        alpha_beta_agent = alpha_beta_search_ordering_agent('x',ordering_middle)\n",
    "        rand_agent = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = rand_agent.act(board)\n",
    "            if utility(board, rand_agent.character) == 1:\n",
    "                winner = rand_agent.character\n",
    "                random_wins = random_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = alpha_beta_agent.act(board)\n",
    "            if utility(board, alpha_beta_agent.character) == 1:\n",
    "                winner = alpha_beta_agent.character\n",
    "                mini_wins = mini_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            show_board(board)\n",
    "    return (mini_wins, random_wins, draws)\n",
    "            \n",
    "play_vs_random(N=1, shape=(4,4),print_boards=False)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(148, 0, 97)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "play_vs_random(N=100, shape=(4,4),print_boards=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search [3 points] \n",
    "\n",
    "### Heuristic evaluation function\n",
    "\n",
    "Define and implement a heuristic evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def score_board(board, player):\n",
    "    #check if there is a horizonatal winner\n",
    "    num_ones_total = 0\n",
    "    num_twos_total = 0\n",
    "    num_threes_total = 0\n",
    "    num_fours_total = 0\n",
    "    for row in board:\n",
    "        num_ones, num_twos, num_threes,num_fours = score_array(row, player)\n",
    "        num_ones_total += num_ones\n",
    "        num_twos_total += num_twos\n",
    "        num_threes_total += num_threes\n",
    "        num_fours_total += num_fours\n",
    "    #print(num_ones_total, num_twos_total, num_threes_total)    \n",
    "    #check if there is a vertical winner\n",
    "    vertical_board = board.copy()\n",
    "    vertical_board = np.rot90(vertical_board)\n",
    "    for row in vertical_board:\n",
    "        num_ones, num_twos, num_threes,num_fours = score_array(row, player)\n",
    "        num_twos_total += num_twos\n",
    "        num_threes_total += num_threes\n",
    "        num_fours_total += num_fours\n",
    "    #print(num_ones_total, num_twos_total, num_threes_total)    \n",
    "\n",
    "    for i in diagonal_rows(board):\n",
    "        num_ones, num_twos, num_threes,num_fours = score_array(i, player)\n",
    "        num_twos_total += num_twos\n",
    "        num_threes_total += num_threes\n",
    "        num_fours_total += num_fours\n",
    "    #print(num_ones_total,num_twos_total,num_threes_total)\n",
    "    #print(num_ones_total, num_twos_total, num_threes_total)    \n",
    "\n",
    "    if num_fours_total > 0:\n",
    "        return 4000, True\n",
    "    return num_twos_total*2 + num_threes_total*100 + num_fours_total*10000, num_fours_total>0\n",
    "\n",
    "def score_array(array, player):\n",
    "    arr = array.copy()\n",
    "    arr = np.insert(arr,obj=0,values=['*'])\n",
    "    arr = np.insert(arr,obj=0,values=['*'])\n",
    "    arr = np.insert(arr,obj=len(arr),values=['*'])\n",
    "    arr = np.insert(arr,obj=len(arr),values=['*'])\n",
    "    \n",
    "    num_ones = 0\n",
    "    num_twos = 0\n",
    "    num_threes = 0\n",
    "    num_fours = 0\n",
    "    current_run = 0\n",
    "    start_char = array[0]\n",
    "    for idx in range(1,len(arr)-1):\n",
    "        c = arr[idx]\n",
    "        if c == player:\n",
    "            current_run += 1\n",
    "        else: \n",
    "            end_char = arr[idx]\n",
    "            if current_run == 1 and (arr[idx] == ' '  or arr[idx-2] == ' ' ):\n",
    "                num_ones += 1\n",
    "            elif current_run == 2 and (arr[idx] == ' '  or arr[idx-3] == ' ' ):\n",
    "                num_twos += 1\n",
    "            elif current_run == 3 and (arr[idx] == ' '  or arr[idx-4] == ' ' ):\n",
    "                num_threes +=1\n",
    "            elif current_run >= 4 and (arr[idx] == ' '  or arr[idx-5] == ' ' ):\n",
    "                num_fours = 1\n",
    "            current_run = 0\n",
    "            start_char = c\n",
    "    return (num_ones,num_twos,num_threes,num_fours)\n",
    "\n",
    "def eval_fun(board, player):\n",
    "    player_score =  score_board(board, player)\n",
    "    oppo_score = score_board(board, switch_player(player))\n",
    "    return player_score[0] - oppo_score[0], player_score[1] or oppo_score[1]\n",
    "def eval_fun_util(board, player):\n",
    "    util = utility(board,player)\n",
    "    if util is None: util = 0\n",
    "    return util, util != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | |\n",
      "| | | | |o|\n",
      "|x|o| | |o|\n",
      "|o|x|o| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3998, True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'o'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'x'\n",
    "board[3][2] = 'o'\n",
    "board[2][0] = 'x'\n",
    "board[4][4] = 'o'\n",
    "board[1][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "board[2][1] = 'o'\n",
    "show_board(board)\n",
    "eval_fun(board,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEBUG = 0 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "\n",
    "def alpha_beta_search_heuristic(board, \n",
    "                                cutoff = None, fp=None,\n",
    "                                ordering=ordering_middle,\n",
    "                                eval_fun=utility, \n",
    "                                player = 'x'):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    value, move = max_value_ab_heuristic(board, player, ordering,eval_fun,-math.inf, +math.inf, 0, cutoff,fp)\n",
    "    \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched (cutoff = {cutoff}): {COUNT}\") \n",
    "    \n",
    "    return value, move\n",
    "\n",
    "def max_value_ab_heuristic(state, player,ordering,eval_fun, alpha, beta, depth, cutoff,fp):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # cut off and terminal test\n",
    "    v, terminal = eval_fun(state, player)\n",
    "    if((fp is not None and v < fp) or (cutoff is not None and depth >= cutoff) or terminal): \n",
    "        if(terminal): alpha, beta = v, v\n",
    "        if DEBUG >= 2: print(f\"stopped at {depth}: {state} term: {terminal} eval: {v} [{alpha}, {beta}]\" ) \n",
    "        return v, None\n",
    "    \n",
    "    v, move = -math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = min_value_ab_heuristic(to_move(state, player, a), player,ordering,eval_fun,alpha, beta, depth + 1, cutoff,fp)\n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta: return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def min_value_ab_heuristic(state, player,ordering,eval_fun, alpha, beta, depth, cutoff,fp):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # cut off and terminal test\n",
    "    v, terminal = eval_fun(state, player)\n",
    "    #if((cutoff is not None and depth >= cutoff) or terminal): \n",
    "    # always let the opponent make her move\n",
    "    if(terminal): \n",
    "        if(terminal): alpha, beta = v, v\n",
    "        if DEBUG >= 2: print(f\"stopped at {depth}: {state} term: {terminal} eval: {v} [{alpha}, {beta}]\" ) \n",
    "        return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = max_value_ab_heuristic(to_move(state, switch_player(player), a), player, ordering,eval_fun,alpha, beta, depth + 1, cutoff,fp)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        if v <= alpha: return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|x| | | | |\n",
      "|x| | | | |\n",
      "|x| | | |o|\n",
      "|o|x|o| |o|\n",
      "|x|x|o| |o|\n",
      "___________\n",
      "(102, False)\n",
      "(4, False)\n",
      "Number of nodes searched (cutoff = 5): 1079\n",
      "(0, 4)\n",
      "Number of nodes searched (cutoff = 5): 559\n",
      "(3998, 2)\n",
      "Wall time: 7.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "board = empty_board((5,5))\n",
    "board[4][0] = 'x'\n",
    "board[4][1] = 'x'\n",
    "board[4][2] = 'o'\n",
    "board[3][0] = 'o'\n",
    "board[3][1] = 'x'\n",
    "board[3][2] = 'o'\n",
    "board[2][0] = 'x'\n",
    "#board[1][4] = 'o'\n",
    "board[4][4] = 'o'\n",
    "board[3][4] = 'o'\n",
    "board[2][4] = 'o'\n",
    "board[1][0] = 'x'\n",
    "board[0][0] = 'x'\n",
    "show_board(board)\n",
    "print(score_board(board, 'o'))\n",
    "print(score_board(board, 'x'))\n",
    "print(alpha_beta_search_heuristic(board, player = 'x', cutoff=5,ordering=ordering_middle,eval_fun=eval_fun))\n",
    "print(alpha_beta_search_heuristic(board, player = 'o', cutoff=5,ordering=ordering_middle,eval_fun=eval_fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class alpha_beta_search_ordering_hue_agent:\n",
    "    def __init__(self,character, ordering,evalfun,cutoff,fp):\n",
    "        self.character = character\n",
    "        self.ordering = ordering\n",
    "        self.eval_fun = evalfun\n",
    "        self.cutoff = cutoff\n",
    "        self.fp = fp\n",
    "    def act(self, board):\n",
    "        win, move_int = alpha_beta_search_heuristic(board, \n",
    "                                                    player=self.character, \n",
    "                                                    ordering=self.ordering,\n",
    "                                                    eval_fun=self.eval_fun,\n",
    "                                                    cutoff=self.cutoff,\n",
    "                                                    fp=self.fp)\n",
    "        if move_int is None:\n",
    "            move_int = rand.choice(actions(board))\n",
    "        return to_move(board, self.character,move_int)\n",
    "test = alpha_beta_search_ordering_hue_agent('x',ordering_middle,eval_fun,5,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[' ', ' ', ' ', ' ', ' ', ' ', ' '],\n",
       "       [' ', ' ', ' ', ' ', ' ', ' ', ' '],\n",
       "       [' ', ' ', ' ', ' ', ' ', ' ', ' '],\n",
       "       [' ', ' ', ' ', ' ', ' ', ' ', ' '],\n",
       "       [' ', ' ', ' ', ' ', ' ', ' ', ' '],\n",
       "       [' ', ' ', ' ', 'x', ' ', ' ', ' ']], dtype='<U1')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = empty_board() \n",
    "print(alpha_beta_search_heuristic(board, player='x',ordering=ordering_middle,eval_fun=eval_fun,cutoff=5))\n",
    "test.act(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| |x| | | |\n",
      "|o|x|o| |o|\n",
      "|x|x|x| |o|\n",
      "|o|x|x| |o|\n",
      "___________\n",
      "|x|o|x|o|x|\n",
      "|o|o|x|o|o|\n",
      "|x|o|x|x|x|\n",
      "|x|x|o|o|o|\n",
      "___________\n",
      "Wall time: 1min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 0, 1)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "DEBUG = 0\n",
    "def hue_vs_random(N=1000, shape=(4,5), print_boards=False):\n",
    "    mini_char = 'o'\n",
    "    random_char = 'x'\n",
    "    mini_wins = 0\n",
    "    random_wins = 0\n",
    "    draws = 0\n",
    "    for i in range(0,N):\n",
    "        board = empty_board(shape=shape)\n",
    "        alpha_beta_agent = alpha_beta_search_ordering_hue_agent('x',ordering_middle,eval_fun,6,None)\n",
    "        rand_agent = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = alpha_beta_agent.act(board)\n",
    "            if utility(board, alpha_beta_agent.character) == 1:\n",
    "                winner = alpha_beta_agent.character\n",
    "                mini_wins = mini_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = rand_agent.act(board)\n",
    "            if utility(board, rand_agent.character) == 1:\n",
    "                winner = rand_agent.character\n",
    "                random_wins = random_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            show_board(board)\n",
    "        \n",
    "        #switch who goes first \n",
    "        board = empty_board(shape=shape)\n",
    "        alpha_beta_agent = alpha_beta_search_ordering_hue_agent('x',ordering_middle,eval_fun,6,None)\n",
    "        rand_agent = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = rand_agent.act(board)\n",
    "            if utility(board, rand_agent.character) == 1:\n",
    "                winner = rand_agent.character\n",
    "                random_wins = random_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = alpha_beta_agent.act(board)\n",
    "            if utility(board, alpha_beta_agent.character) == 1:\n",
    "                winner = alpha_beta_agent.character\n",
    "                mini_wins = mini_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            show_board(board)\n",
    "    return (mini_wins, random_wins, draws)\n",
    "\n",
    "hue_vs_random(N=1, shape=(4,5), print_boards=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36mhue_vs_random\u001b[1;34m(N, shape, print_boards)\u001b[0m\n",
      "\u001b[1;32m<ipython-input-164-037cf7284001>\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, board)\u001b[0m\n\u001b[0;32m     12\u001b[0m                                                     \u001b[0meval_fun\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_fun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                                                     \u001b[0mcutoff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                                                     fp=self.fp)\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmove_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mmove_int\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-155-4fda9866f28a>\u001b[0m in \u001b[0;36malpha_beta_search_heuristic\u001b[1;34m(board, cutoff, fp, ordering, eval_fun, player)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCOUNT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mCOUNT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab_heuristic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_fun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Number of nodes searched (cutoff = {cutoff}): {COUNT}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-155-4fda9866f28a>\u001b[0m in \u001b[0;36mmax_value_ab_heuristic\u001b[1;34m(state, player, ordering, eval_fun, alpha, beta, depth, cutoff, fp)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab_heuristic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_fun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-155-4fda9866f28a>\u001b[0m in \u001b[0;36mmin_value_ab_heuristic\u001b[1;34m(state, player, ordering, eval_fun, alpha, beta, depth, cutoff, fp)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab_heuristic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_fun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-155-4fda9866f28a>\u001b[0m in \u001b[0;36mmax_value_ab_heuristic\u001b[1;34m(state, player, ordering, eval_fun, alpha, beta, depth, cutoff, fp)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab_heuristic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_fun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-155-4fda9866f28a>\u001b[0m in \u001b[0;36mmin_value_ab_heuristic\u001b[1;34m(state, player, ordering, eval_fun, alpha, beta, depth, cutoff, fp)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# check all possible actions in the state, update beta and return move with the smallest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_value_ab_heuristic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_fun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-155-4fda9866f28a>\u001b[0m in \u001b[0;36mmax_value_ab_heuristic\u001b[1;34m(state, player, ordering, eval_fun, alpha, beta, depth, cutoff, fp)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# check all possible actions in the state, update alpha and return move with the largest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_value_ab_heuristic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordering\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_fun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-155-4fda9866f28a>\u001b[0m in \u001b[0;36mmin_value_ab_heuristic\u001b[1;34m(state, player, ordering, eval_fun, alpha, beta, depth, cutoff, fp)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m# cut off and terminal test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[1;31m#if((cutoff is not None and depth >= cutoff) or terminal):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# always let the opponent make her move\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-bc46b4b88192>\u001b[0m in \u001b[0;36meval_fun\u001b[1;34m(board, player)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0meval_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mplayer_score\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mscore_board\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0moppo_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_board\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch_player\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mplayer_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0moppo_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0moppo_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0meval_fun_util\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-bc46b4b88192>\u001b[0m in \u001b[0;36mscore_board\u001b[1;34m(board, player)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdiagonal_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mnum_ones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_twos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_threes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_fours\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mnum_twos_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnum_twos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mnum_threes_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnum_threes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-bc46b4b88192>\u001b[0m in \u001b[0;36mscore_array\u001b[1;34m(array, player)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'*'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'*'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'*'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mnum_ones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minsert\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(arr, obj, values, axis)\u001b[0m\n\u001b[0;32m   4597\u001b[0m         \u001b[0mslobj2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4598\u001b[0m         \u001b[0mslobj2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4599\u001b[1;33m         \u001b[0mnew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4600\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4601\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hue_vs_random(N=20, shape=(5,5), print_boards=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting off search \n",
    "\n",
    "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n",
      "Number of nodes searched (cutoff = 5): 4285\n",
      "(0, 3)\n",
      "Wall time: 26.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global DEBUG\n",
    "DEBUG = 1\n",
    "board = empty_board((6,7))\n",
    "show_board(board)\n",
    "print(alpha_beta_search_heuristic(board, player='x', cutoff=5, ordering=ordering_middle, \n",
    "                                  eval_fun=eval_fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without more analysis we are going to take this test and claim that 5 is a good cutoff.  The reason fo this is because the search was able to find what we \"think\" is the best move on a blank board.  That is the 4th column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with the same manually created boards as above to check if the agent spots wining opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes searched (cutoff = 5): 293\n",
      "(3800, 0)\n",
      "| | | |o| | | |\n",
      "| | | |x| | | |\n",
      "| | | |o| | | |\n",
      "| |x|o|x| | | |\n",
      "| |o|x|o| | | |\n",
      "| |x|x|x|o| | |\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "board = empty_board((6,7))\n",
    "board = to_move(board,'x',3)\n",
    "board = to_move(board,'o',3)\n",
    "board = to_move(board,'x',3)\n",
    "board = to_move(board,'o',3)\n",
    "board = to_move(board,'x',3)\n",
    "board = to_move(board,'o',3)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',4)\n",
    "board = to_move(board,'x',2)\n",
    "board = to_move(board,'o',2)\n",
    "board = to_move(board,'x',1)\n",
    "board = to_move(board,'o',1)\n",
    "board = to_move(board,'x',1)\n",
    "\n",
    "\n",
    "move = alpha_beta_search_heuristic(board, player='o', cutoff=5, ordering=ordering_middle, \n",
    "                                  eval_fun=eval_fun)\n",
    "\n",
    "print(move)\n",
    "show_board(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pruning\n",
    "\n",
    "Add forward pruning to the cutoff search where you do not consider moves that have a low evaluation value after a shallow search \n",
    "(way smaller than the cuttoff value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n",
      "Number of nodes searched (cutoff = 5): 4285\n",
      "(0, 3)\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global DEBUG\n",
    "DEBUG = 1\n",
    "board = empty_board((6,7))\n",
    "show_board(board)\n",
    "print(alpha_beta_search_heuristic(board, player='x', cutoff=5, ordering=ordering_original, fp=-10,\n",
    "                                  eval_fun=eval_fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n",
      "Number of nodes searched (cutoff = 5): 4285\n",
      "(0, 3)\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global DEBUG\n",
    "DEBUG = 1\n",
    "board = empty_board((6,7))\n",
    "show_board(board)\n",
    "print(alpha_beta_search_heuristic(board, player='x', cutoff=5, ordering=ordering_original, fp=-2,\n",
    "                                  eval_fun=eval_fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n",
      "Number of nodes searched (cutoff = 5): 3464\n",
      "(0, 3)\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global DEBUG\n",
    "DEBUG = 1\n",
    "board = empty_board((6,7))\n",
    "show_board(board)\n",
    "print(alpha_beta_search_heuristic(board, player='x', cutoff=5, ordering=ordering_original, fp=-1,\n",
    "                                  eval_fun=eval_fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n",
      "Number of nodes searched (cutoff = 5): 3464\n",
      "(0, 3)\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global DEBUG\n",
    "DEBUG = 1\n",
    "board = empty_board((6,7))\n",
    "show_board(board)\n",
    "print(alpha_beta_search_heuristic(board, player='x', cutoff=5, ordering=ordering_original, fp=0,\n",
    "                                  eval_fun=eval_fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the foward pruning\n",
    "\n",
    "Instead of playing on a bunch of board, like we did for the cutoff we are just going to analize how long it takes to move on the blank board.\n",
    "\n",
    "We can see that with a prunning value of -10, we actually didn't make any progress and still had to expand the same number of nodes to  get to then answer of 3.  With -1 however you can see the algorithm search about 800 less nodes in the tree and with 0 we we get the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function or different forward pruning) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 0, 0)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def hue_prun_vs_random(N=1000, shape=(4,4), print_boards=False):\n",
    "    mini_char = 'o'\n",
    "    random_char = 'x'\n",
    "    mini_wins = 0\n",
    "    random_wins = 0\n",
    "    draws = 0\n",
    "    for i in range(0,N):\n",
    "        board = empty_board(shape=shape)\n",
    "        alpha_beta_agent = alpha_beta_search_ordering_hue_agent('x',ordering_middle,eval_fun,6,-5)\n",
    "        rand_agent = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = alpha_beta_agent.act(board)\n",
    "            if utility(board, alpha_beta_agent.character) == 1:\n",
    "                winner = alpha_beta_agent.character\n",
    "                mini_wins = mini_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = rand_agent.act(board)\n",
    "            if utility(board, rand_agent.character) == 1:\n",
    "                winner = rand_agent.character\n",
    "                random_wins = random_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            show_board(board)\n",
    "        \n",
    "        #switch who goes first \n",
    "        board = empty_board(shape=shape)\n",
    "        alpha_beta_agent = alpha_beta_search_ordering_hue_agent('x',ordering_middle,eval_fun,5,-5)\n",
    "        rand_agent = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = rand_agent.act(board)\n",
    "            if utility(board, rand_agent.character) == 1:\n",
    "                winner = rand_agent.character\n",
    "                random_wins = random_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = alpha_beta_agent.act(board)\n",
    "            if utility(board, alpha_beta_agent.character) == 1:\n",
    "                winner = alpha_beta_agent.character\n",
    "                mini_wins = mini_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            show_board(board)\n",
    "    return (mini_wins, random_wins, draws)\n",
    "\n",
    "hue_prun_vs_random(N=1, shape=(4,5), print_boards=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 0, 0)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hue_prun_vs_random(N=20, shape=(6,7), print_boards=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Monte Carlos Search\n",
    "\n",
    "Implement Pure Monte Carlo Search and investigate how this search performs on the test boards that you have used above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [1 point]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+1 Bonus point].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "global DEBUG\n",
    "DEBUG = 0\n",
    "def playout(state, action, player = 'x'):\n",
    "    \"\"\"Perfrom a random playout starting with the given action on the fiven board \n",
    "    and return the utility of the finished game.\"\"\"\n",
    "    state = to_move(state, player, action)\n",
    "    current_player = switch_player(player)\n",
    "    \n",
    "    while(True):\n",
    "        # reached terminal state?\n",
    "        u = utility(state, player)\n",
    "        if u is not None: return(u)\n",
    "        \n",
    "        # we use a random playout policy\n",
    "        a = np.random.choice(actions(state))\n",
    "        state = to_move(state, current_player, a)\n",
    "        #print(state)\n",
    "        \n",
    "        # switch between players\n",
    "        current_player = switch_player(current_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playouts(board, action, player = 'x', N = 100):\n",
    "    \"\"\"Perform N playouts following the given action for the given board.\"\"\"\n",
    "    return [ playout(board, action, player) for i in range(N) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmcs(board, N = 100, player = 'x'):\n",
    "    \"\"\"Pure Monte Carlo Search. Returns the action that has the largest average utility.\n",
    "    The N playouts are evenly divided between the possible actions.\"\"\"\n",
    "    global DEBUG\n",
    "    \n",
    "    avail_actions = actions(board)\n",
    "    n = math.floor(N/len(avail_actions))\n",
    "    if DEBUG >= 1: print(f\"Actions: {avail_actions} ({n} playouts per actions)\")\n",
    "    \n",
    "    ps = { i:np.mean(playouts(board, i, player, N = n)) for i in avail_actions }\n",
    "    if DEBUG >= 1: display(ps)\n",
    "        \n",
    "    action = max(ps, key=ps.get)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class monte_agent:\n",
    "    def __init__(self,character, N):\n",
    "        self.character = character\n",
    "        self.N = N\n",
    "    \n",
    "    def act(self, board):\n",
    "        move = pmcs(board, self.N, self.character)\n",
    "        return to_move(board, self.character, move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | |o| | | |\n",
      "| | | |x| | | |\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | |o| | | |\n",
      "| | | |x|x| |o|\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | |o| | | |\n",
      "|o| |x|x|x| |o|\n",
      "_______________\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | | | | | |\n",
      "| | | |o|o| | |\n",
      "|o|x|x|x|x| |o|\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "monte = monte_agent('x', 100)\n",
    "random = random_agent('o')\n",
    "board = empty_board() \n",
    "show_board(board)\n",
    "winner = False\n",
    "while(len(actions(board)) != 0 and not winner):\n",
    "    board = monte.act(board)\n",
    "    board = random.act(board)\n",
    "    winner = utility(board, monte.character) is not None\n",
    "    show_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_vs_monte(N=1000, monte_size=100,shape=(6,7), print_boards=False):\n",
    "    mini_char = 'o'\n",
    "    random_char = 'x'\n",
    "    mini_wins = 0\n",
    "    random_wins = 0\n",
    "    draws = 0\n",
    "    for i in range(0,N):\n",
    "        board = empty_board(shape=shape)\n",
    "        monte = monte_agent('x', monte_size)\n",
    "        rand_agent = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = monte.act(board)\n",
    "            if utility(board, monte.character) == 1:\n",
    "                winner = monte.character\n",
    "                mini_wins = mini_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = rand_agent.act(board)\n",
    "            if utility(board, rand_agent.character) == 1:\n",
    "                winner = rand_agent.character\n",
    "                random_wins = random_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            show_board(board)\n",
    "        \n",
    "        #switch who goes first \n",
    "        board = empty_board(shape=shape)\n",
    "        monte = monte_agent('x', monte_size)\n",
    "        rand_agent = random_agent('o')\n",
    "        winner = ' '\n",
    "        while winner == ' ':\n",
    "            board = rand_agent.act(board)\n",
    "            if utility(board, rand_agent.character) == 1:\n",
    "                winner = rand_agent.character\n",
    "                random_wins = random_wins + 1\n",
    "            if winner == ' ':\n",
    "                board = monte.act(board)\n",
    "            if utility(board, monte.character) == 1:\n",
    "                winner = monte.character\n",
    "                mini_wins = mini_wins + 1\n",
    "            if len(actions(board)) == 0:\n",
    "                winner = 'd'\n",
    "                draws = draws + 1\n",
    "        if print_boards:\n",
    "            show_board(board)\n",
    "    return (mini_wins, random_wins, draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 0, 0)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "play_vs_monte(N=50,monte_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Move\n",
    "\n",
    "How would you determine what the best first move is? You can use Pure Monte Carlo Search or any algorithms \n",
    "that you have implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple I would make the monte carlo search make the first move and give it time till the percentages don't seem to change.\n",
    "def pmcs_full_return(board, N = 100, player = 'x'):\n",
    "    \"\"\"Pure Monte Carlo Search. Returns the action that has the largest average utility.\n",
    "    The N playouts are evenly divided between the possible actions.\"\"\"\n",
    "    \n",
    "    avail_actions = actions(board)\n",
    "    n = math.floor(N/len(avail_actions))\n",
    "    #if DEBUG >= 1: print(f\"Actions: {avail_actions} ({n} playouts per actions)\")\n",
    "    \n",
    "    ps = { i:np.mean(playouts(board, i, player, N = n)) for i in avail_actions }\n",
    "    #if DEBUG >= 1: display(ps)\n",
    "        \n",
    "    action = max(ps, key=ps.get)\n",
    "    return ps\n",
    "\n",
    "board = empty_board()\n",
    "monte_size = 1000\n",
    "last_run = pmcs_full_return(board,monte_size,'x')\n",
    "last_run = last_run.values()\n",
    "last_run = np.array(list(last_run))\n",
    "cont = True\n",
    "runs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-180-75d050365783>\u001b[0m in \u001b[0;36mpmcs_full_return\u001b[1;34m(board, N, player)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#if DEBUG >= 1: print(f\"Actions: {avail_actions} ({n} playouts per actions)\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mavail_actions\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#if DEBUG >= 1: display(ps)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-180-75d050365783>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#if DEBUG >= 1: print(f\"Actions: {avail_actions} ({n} playouts per actions)\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mavail_actions\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#if DEBUG >= 1: display(ps)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-176-555cafd16102>\u001b[0m in \u001b[0;36mplayouts\u001b[1;34m(board, action, player, N)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplayouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Perform N playouts following the given action for the given board.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mplayout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-176-555cafd16102>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplayouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Perform N playouts following the given action for the given board.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mplayout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-175-d9e6bd9d57b8>\u001b[0m in \u001b[0;36mplayout\u001b[1;34m(state, action, player)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# we use a random playout policy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_player\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;31m#print(state)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-86c419e95300>\u001b[0m in \u001b[0;36mto_move\u001b[1;34m(board, player, move)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mto_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mnew_board\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_board\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cont = True\n",
    "while cont:\n",
    "    current_run = pmcs_full_return(board,monte_size,'x')\n",
    "    current_run = current_run.values()\n",
    "    current_run = np.array(list(current_run))\n",
    "    norm_diff = np.linalg.norm(last_run - current_run)    \n",
    "    runs.append([monte_size,norm_diff])\n",
    "    \n",
    "    if norm_diff < .01:\n",
    "        cont = False\n",
    "    last_run = current_run\n",
    "    monte_size *= 1.1\n",
    "    #print(monte_size, norm_diff)\n",
    "print(last_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.01634684,  0.13361763,  0.13574982,  0.28287136,  0.14143568,\n",
       "        0.12153518, -0.02203269])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = [i[0] for i in runs]\n",
    "y = [i[1] for i in runs]\n",
    "y_bottom = [.01] * len(runs) \n",
    "plt.plot(x,y,x,y_bottom)\n",
    "plt.show()\n",
    "last_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monte_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge task [+ 1 bonus point]\n",
    "\n",
    "Find another student and let your best agent play against the other student's best player. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0,'./')\n",
    "\n",
    "import mini_max_nick5 as nick\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Steven\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1321, in time\n",
      "    exec(code, glob, local_ns)\n",
      "  File \"<timed exec>\", line 18, in <module>\n",
      "NameError: name 'end' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Steven\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Steven\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Steven\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Steven\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Steven\\anaconda3\\envs\\mlenv2020\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Steven\\anaconda3\\envs\\mlenv2020\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Steven\\anaconda3\\envs\\mlenv2020\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\Steven\\anaconda3\\envs\\mlenv2020\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m                 \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'end' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2044\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2045\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2046\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NameError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-184-f9d1d12ac057>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"nick_agent = nick.ABAgent(H=nick.basic_heuristic,cutoff=5,fp=5)\\nsteven_agent = monte_agent('o', 5000)\\nnumber_of_games = 2\\n\\nnick_wins = 0\\nnick_time = 0.0\\nsteven_wins = 0\\nsteven_time =0.0\\nfor i in range(number_of_games):\\n    board = empty_board()\\n    nick_char = 'x'\\n    steven_char ='o'\\n    end_game = False\\n    while end_game == False:\\n        start_time = time.time\\n        board = to_move(board,nick_char,nick_agent.act(board,nick_char))\\n        end_time = time.time\\n        nick_time += (end-start)\\n        \\n        start_time = time.time        \\n        board = steven_agent.act(board)\\n        end_time = time.time\\n        nick_time += (end-start)\\n        util = utility(board,nick_char)\\n        if util == 1:\\n            nick_wins += 1\\n            end_game = True\\n        elif util == -1:\\n            steven_wins += 1\\n            end_game = True\\n        \\n    end_game = False\\n    board = empty_board()\\n    while end_game == False:\\n        board = to_move(board,nick_char,nick_agent.act(board,nick_char))\\n        board = steven_agent.act(board)\\n        util = utility(board,nick_char)\\n        if util == 1:\\n            nick_wins += 1\\n            end_game = True\\n        elif util == -1:\\n            steven_wins += 1\\n            end_game = True\\n    \\n    \\nprint('Nick won', nick_wins, 'times, with an average think time of', nick_time/(number_of_games*2))\\nprint('Steven won', steven_wins, 'times, with an average think time of', steven_time/(number_of_games*2))\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2380\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2381\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2382\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2383\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-55>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1328\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2046\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2047\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2048\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2050\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1437\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1335\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1337\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1338\u001b[0m             )\n\u001b[0;32m   1339\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1194\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2020\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nick_agent = nick.ABAgent(H=nick.basic_heuristic,cutoff=5,fp=5)\n",
    "steven_agent = monte_agent('o', 5000)\n",
    "number_of_games = 2\n",
    "\n",
    "nick_wins = 0\n",
    "nick_time = 0.0\n",
    "steven_wins = 0\n",
    "steven_time =0.0\n",
    "for i in range(number_of_games):\n",
    "    board = empty_board()\n",
    "    nick_char = 'x'\n",
    "    steven_char ='o'\n",
    "    end_game = False\n",
    "    while end_game == False:\n",
    "        start_time = time.time\n",
    "        board = to_move(board,nick_char,nick_agent.act(board,nick_char))\n",
    "        end_time = time.time\n",
    "        nick_time += (end-start)\n",
    "        \n",
    "        start_time = time.time        \n",
    "        board = steven_agent.act(board)\n",
    "        end_time = time.time\n",
    "        nick_time += (end-start)\n",
    "        util = utility(board,nick_char)\n",
    "        if util == 1:\n",
    "            nick_wins += 1\n",
    "            end_game = True\n",
    "        elif util == -1:\n",
    "            steven_wins += 1\n",
    "            end_game = True\n",
    "        \n",
    "    end_game = False\n",
    "    board = empty_board()\n",
    "    while end_game == False:\n",
    "        board = to_move(board,nick_char,nick_agent.act(board,nick_char))\n",
    "        board = steven_agent.act(board)\n",
    "        util = utility(board,nick_char)\n",
    "        if util == 1:\n",
    "            nick_wins += 1\n",
    "            end_game = True\n",
    "        elif util == -1:\n",
    "            steven_wins += 1\n",
    "            end_game = True\n",
    "    \n",
    "    \n",
    "print('Nick won', nick_wins, 'times, with an average think time of', nick_time/(number_of_games*2))\n",
    "print('Steven won', steven_wins, 'times, with an average think time of', steven_time/(number_of_games*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
